{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a6b4af-1c00-4c20-a7ee-d78941ddb4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a23f1fd6-c48e-43ca-aa0b-a161afe89b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FallbackHandler():\n",
    "    \"\"\"\n",
    "    A class representing a standalone handler for processing standalone questions.\n",
    "    Inherits from PrivateHandler.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def predict(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate a fallback message based on the input message.\n",
    "\n",
    "        Args:\n",
    "            message (str): The input message.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated message.\n",
    "        \"\"\"\n",
    "\n",
    "        return (\n",
    "            \"Desculpe, mas não posso responder a essa pergunta. \"\n",
    "            \"Algo em que possa ajudar sobre notícias de Poços de Caldas e região?\"\n",
    "        )\n",
    "\n",
    "\n",
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from bot.handlers import PublicHandler\n",
    "from bot.vector_databases.base import VectorDB\n",
    "\n",
    "\n",
    "class GreetingHandler(PublicHandler):\n",
    "    \"\"\"\n",
    "    A class representing a query handler for processing user queries.\n",
    "    Inherits from PublicHandler.\n",
    "    \"\"\"\n",
    "\n",
    "    _prompt_key: str = \"prompt_greeting\"\n",
    "    _use_chat_history: bool = True\n",
    "    _use_context: bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_model: str,\n",
    "        memory: BaseChatMemory,\n",
    "        vector_database: VectorDB,\n",
    "        temperature: float = 0,\n",
    "        verbose: bool = True,\n",
    "        llm_context_window_size: int = 4096,\n",
    "        prompt_max_tokens: int = 3200,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the GreetingHandler.\n",
    "\n",
    "        Args:\n",
    "            llm_model (str): The language model for processing queries.\n",
    "            memory (BaseChatMemory): The chat memory.\n",
    "            vector_database (VectorDB): The vector database for query processing.\n",
    "            temperature (float): The temperature for generating responses.\n",
    "            verbose (bool): Whether to enable verbose mode.\n",
    "            llm_context_window_size (int): The context window size for the language model.\n",
    "            prompt_max_tokens (int): The maximum tokens for a prompt.\n",
    "        \"\"\"\n",
    "        self._llm_model = llm_model\n",
    "        self._memory = memory\n",
    "        self._temperature = temperature\n",
    "        self._verbose = verbose\n",
    "        self._vector_database = vector_database\n",
    "        self._llm_context_window_size = llm_context_window_size\n",
    "        self._prompt_max_tokens = prompt_max_tokens\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "\n",
    "    @property\n",
    "    def verbose(self):\n",
    "        return self._verbose\n",
    "\n",
    "    @property\n",
    "    def llm_model(self):\n",
    "        return self._llm_model\n",
    "\n",
    "    @property\n",
    "    def memory(self):\n",
    "        return self._memory\n",
    "\n",
    "    @property\n",
    "    def vector_database(self):\n",
    "        return self._vector_database\n",
    "\n",
    "    @property\n",
    "    def prompt_key(self):\n",
    "        return self._prompt_key\n",
    "\n",
    "    @property\n",
    "    def use_chat_history(self):\n",
    "        return self._use_chat_history\n",
    "\n",
    "    @property\n",
    "    def use_context(self):\n",
    "        return self._use_context\n",
    "\n",
    "    @property\n",
    "    def llm_context_window_size(self):\n",
    "        return self._llm_context_window_size\n",
    "\n",
    "    @property\n",
    "    def prompt_max_tokens(self):\n",
    "        return self._prompt_max_tokens\n",
    "\n",
    "    @property\n",
    "    def llm(self):\n",
    "        return ChatOpenAI(model_name=self.llm_model, temperature=self.temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b436e3-317d-489c-b509-5d7abc91b69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c30951d-1c11-4cef-b618-8a3ffac4f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "from importlib import resources\n",
    "from uuid import uuid4\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "import langchain_core\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.memory import ConversationSummaryBufferMemory, ChatMessageHistory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import load_prompt\n",
    "from loguru import logger\n",
    "import tiktoken\n",
    "from bot import BotConfig\n",
    "from bot.local_memory import LocalMemory\n",
    "\n",
    "\n",
    "config = BotConfig()\n",
    "\n",
    "LLM_CONTEXT_WINDOW_SIZE = 4096\n",
    "PROMPT_MAX_TOKENS = 3200\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_prompt(key):\n",
    "    filepath = str(resources.files(\"bot.prompts\").joinpath(f\"{key}.json\"))\n",
    "    return load_prompt(filepath)\n",
    "\n",
    "\n",
    "class NewsBot:\n",
    "    def __init__(self, verbose: bool = True):\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.vdb = get_vector_database(\"chroma\")\n",
    "\n",
    "\n",
    "        self.memory = ConversationSummaryBufferMemory(\n",
    "                    llm=OpenAI(temperature=0),\n",
    "                    chat_history=ChatMessageHistory(),\n",
    "                    return_messages=True,\n",
    "                    memory_key=\"chat_history\",\n",
    "                    input_key=\"human_input\",\n",
    "                    human_prefix=config.HUMAN_PREFIX,\n",
    "                    ai_prefix=config.AI_PREFIX,\n",
    "                )\n",
    "\n",
    "        self.standalone_handler = StandaloneHandler(llm_model=config.LLM_MODEL_NAME, memory=self.memory, verbose=verbose)\n",
    "        self.intention_handler = IntentionHandler(llm_model=config.LLM_MODEL_NAME, memory=self.memory, verbose=verbose)\n",
    "        self.query_handler = QueryHandler(llm_model=config.LLM_MODEL_NAME, memory=self.memory, vector_database=self.vdb, verbose=verbose)\n",
    "        self.greeting_handler = GreetingHandler(llm_model=config.LLM_MODEL_NAME, memory=self.memory, vector_database=self.vdb, verbose=verbose)\n",
    "        self.fallback_handler = FallbackHandler()\n",
    "\n",
    "\n",
    "    def execute(self, message: str):\n",
    "\n",
    "        improved_message = self.standalone_handler.predict(message)\n",
    "        logger.debug(f\"Pergunta original: {message}\")\n",
    "        logger.debug(f\"Pergunta melhorada: {improved_message}\")\n",
    "\n",
    "        intention = self.intention_handler.predict(improved_message)\n",
    "        logger.debug(f\"Intenção: {intention}\")\n",
    "\n",
    "        handlers = {\n",
    "            \"inicio de conversa\": self.greeting_handler,\n",
    "            \"consulta de conteudo\": self.query_handler,\n",
    "            \"\": self.fallback_handler,\n",
    "        }\n",
    "\n",
    "        response = None\n",
    "        for category, handler in handlers.items():\n",
    "            if category in intention.lower().replace(\"ú\", \"u\").replace(\"í\", \"i\"):\n",
    "                response = handler.predict(improved_message)\n",
    "                break\n",
    "\n",
    "        return dict(response=response, execution_id=uuid4().hex)\n",
    "\n",
    "\n",
    "def extract_dict_from_string(string):\n",
    "    \"\"\"\n",
    "    Extrai um elemento JSON de uma string.\n",
    "\n",
    "    Args:\n",
    "    string: A string que contém o elemento JSON.\n",
    "\n",
    "    Returns:\n",
    "    O elemento JSON como um dicionário Python, ou None se não for possível extrair.\n",
    "    \"\"\"\n",
    "\n",
    "    match = re.search(r\"{([^}]+)}\", string)\n",
    "    if match is None:\n",
    "        return dict()\n",
    "\n",
    "    json_content = match.group(1)\n",
    "\n",
    "    try:\n",
    "        json_dict = json.loads(\"{\" + json_content + \"}\")\n",
    "        return json_dict\n",
    "    except json.JSONDecodeError as err:\n",
    "        logger.error(str(err))\n",
    "        return dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ed7395a-ae7a-44df-90d9-8df486bd7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_bot = NewsBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddfc23da-e4da-4572-b53a-96fcb4a7ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce vai receber uma pergunta de follow up do usuario, que pode nao ter muitos detalhes.\n",
      "O usuario quer realizar consultas na base de dados que contem noticias de Pocos de Caldas e regiao.\n",
      "Alguns usuarios costumam iniciar as conversas como uma saudacao, como `Ola. Tudo bem?`, por exemplo.\n",
      "Caso o `HUMAN INPUT` seja uma saudacao, faca apenas uma correcao ortografica. Caso contrário, REESCREVA a frase do `HUMAN INPUT` para que ela possa ser considerada uma pergunta independente. \n",
      "Inclua o maximo de detalhes possivel a partir do `CHAT HISTORY`, como contexto, data, titulo e autor da noticia.\n",
      "EM HIPÓTESE ALGUMA responda a pergunta em `HUMAN INPUT` ao usuário, APENAS REESCREVA A PERGUNTA.\n",
      "Sua resposta deve conter apenas a `HUMAN INPUT` reescrita.\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Olá`\n",
      "\n",
      "IA: A forma reescrita do `HUMAN INPUT` é \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-09 02:07:59.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m68\u001b[0m - \u001b[34m\u001b[1mPergunta original: Olá\u001b[0m\n",
      "\u001b[32m2024-01-09 02:07:59.997\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m69\u001b[0m - \u001b[34m\u001b[1mPergunta melhorada: Olá. Tudo bem?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnalise a mensagem do usuario em \"HUMAN INPUT\" e o \"CHAT HISTORY\" e classifique a intencao de acordo com as seguintes categorias:\n",
      "\n",
      "- \"Inicio de conversa\": Saudacoes e cumprimentos do usuario, reconheca frases como \"oi\", \"ola\", \"bom dia\", \"tudo bem:\", etc.\n",
      "- \"Consulta de conteudo\": Perguntas sobre noticias da base de dados, reconheca trechos como \"quais sao as ultimas noticias\", \"o que foi reportado no bairro\", etc.\n",
      "- \"\": QUALQUER PERGUNTA QUE NAO SE ENCAIXE NAS CATEGORIAS ACIMA, ou que nao possa ser respondida com o contexto disponivel na base de dados, a qual contem noticias de Pocos de Caldas e regiao.\n",
      "\n",
      "Escolha apenas uma das opcoes. Sua resposta deve conter APENAS a categoria.\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Olá. Tudo bem?`\n",
      "\n",
      "IA:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-09 02:08:00.916\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mIntenção: Inicio de conversa\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce e um chatbot que possui conhecimento das noticias de Pocos de Caldas e regiao.\n",
      "Responda a mensagem do usuario em HUMAN INPUT de maneira cordial e simpatica..\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Olá. Tudo bem?`\n",
      "\n",
      "IA:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'Olá! Tudo bem sim, obrigado por perguntar! Como posso ajudar você hoje?',\n",
       " 'execution_id': '575deac7255b4831b5d2d19b7777e4dd'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bot.execute(\"Olá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe99ee61-55fa-4585-9ad3-69b6df7188b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce vai receber uma pergunta de follow up do usuario, que pode nao ter muitos detalhes.\n",
      "O usuario quer realizar consultas na base de dados que contem noticias de Pocos de Caldas e regiao.\n",
      "Alguns usuarios costumam iniciar as conversas como uma saudacao, como `Ola. Tudo bem?`, por exemplo.\n",
      "Caso o `HUMAN INPUT` seja uma saudacao, faca apenas uma correcao ortografica. Caso contrário, REESCREVA a frase do `HUMAN INPUT` para que ela possa ser considerada uma pergunta independente. \n",
      "Inclua o maximo de detalhes possivel a partir do `CHAT HISTORY`, como contexto, data, titulo e autor da noticia.\n",
      "EM HIPÓTESE ALGUMA responda a pergunta em `HUMAN INPUT` ao usuário, APENAS REESCREVA A PERGUNTA.\n",
      "Sua resposta deve conter apenas a `HUMAN INPUT` reescrita.\n",
      "\n",
      "## CHAT HISTORY\n",
      "```Human: Olá. Tudo bem?\n",
      "AI: Olá! Tudo bem sim, obrigado por perguntar! Como posso ajudar você hoje?\n",
      "```\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Pode me dar algumas notícias sobre acidentes?`\n",
      "\n",
      "IA: A forma reescrita do `HUMAN INPUT` é \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-09 02:08:08.083\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m68\u001b[0m - \u001b[34m\u001b[1mPergunta original: Pode me dar algumas notícias sobre acidentes?\u001b[0m\n",
      "\u001b[32m2024-01-09 02:08:08.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m69\u001b[0m - \u001b[34m\u001b[1mPergunta melhorada: Quais são as notícias mais recentes sobre acidentes em Poços de Caldas e região?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnalise a mensagem do usuario em \"HUMAN INPUT\" e o \"CHAT HISTORY\" e classifique a intencao de acordo com as seguintes categorias:\n",
      "\n",
      "- \"Inicio de conversa\": Saudacoes e cumprimentos do usuario, reconheca frases como \"oi\", \"ola\", \"bom dia\", \"tudo bem:\", etc.\n",
      "- \"Consulta de conteudo\": Perguntas sobre noticias da base de dados, reconheca trechos como \"quais sao as ultimas noticias\", \"o que foi reportado no bairro\", etc.\n",
      "- \"\": QUALQUER PERGUNTA QUE NAO SE ENCAIXE NAS CATEGORIAS ACIMA, ou que nao possa ser respondida com o contexto disponivel na base de dados, a qual contem noticias de Pocos de Caldas e regiao.\n",
      "\n",
      "Escolha apenas uma das opcoes. Sua resposta deve conter APENAS a categoria.\n",
      "\n",
      "## CHAT HISTORY\n",
      "```Human: Olá. Tudo bem?\n",
      "AI: Olá! Tudo bem sim, obrigado por perguntar! Como posso ajudar você hoje?\n",
      "```\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Quais são as notícias mais recentes sobre acidentes em Poços de Caldas e região?`\n",
      "\n",
      "IA:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-09 02:08:08.698\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mIntenção: Consulta de conteúdo\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce e um chatbot que responde sobre noticias da cidade de Pocos de Caldas.\n",
      "\n",
      "Sua tarefa e responder a mensagem do usuário em HUMAN INPUT utilizando o CONTEXTO providenciado.\n",
      "Considere o CHAT HISTORY.\n",
      "Nao responda nada que nao esteja no contexto. Se o contexto nao tiver informacoes relevantes a pergunta do usuario, responda \"nao sei\".\n",
      "Nao considere nenhuma noticia que nao seja de Pocos de Caldas.\n",
      "\n",
      "Formate sua resposta como um JSON conforme indicado abaxo:\n",
      "{\n",
      "    \"resposta\": \"sua resposta aqui\",\n",
      "    \"link\": \"link da noticia que voce usou para elaborar sua resposta\",\n",
      "    \"data\": \"data da noticia\",\n",
      "    \"titulo\": \"titulo da noticia\",\n",
      "    \"autor\": \"autor da noticia\"\n",
      "}\n",
      "Nao responda nada alem do JSON.\n",
      "\n",
      "## CONTEXTO\n",
      "```\n",
      "<noticia_1>\n",
      "\t<data>2022-06-26</data>\n",
      "\t<titulo>Acidente é registrado em Poços de Caldas</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/acidente-e-registrado-em-pocos-de-caldas/</link>\n",
      "\t<conteudo>Foi registrado na tarde deste sábado um acidente de carro em Poços de Caldas. As primeiras informações são de que o acidente ocorreu na Avenida Leonor Furlaneto Delgado, mais conhecida como estrada da Cachoeirinha. A Polícia Militar compareceu ao local. A ocorrência segue em andamento. (Reportagem em atualização) </conteudo>\n",
      "</noticia_1>\n",
      "\n",
      "<noticia_2>\n",
      "\t<data>2022-09-22</data>\n",
      "\t<titulo>É falsa informação sobre assassinato de três ladrões de motos em Poços de Caldas</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/e-falsa-informacao-sobre-assassinato-de-tres-ladroes-de-motos-em-pocos-de-caldas/</link>\n",
      "\t<conteudo>Circula pelas redes sociais e aplicativos de conversa, um vídeo com informações de que três ladrões de motos foram executados em Poços de Caldas. Mas de acordo com apuração feita pelo jornalismo da Onda Poços junto à polícia, as informações são falsas. O crime, na verdade, foi registrado na cidade de Americana-SP, onde três homens foram encontrados com mãos e pés amarrados e com marcas de tiro às margens da Rodovia Ivo Macris, na manhã de quarta-feira (14). A Polícia Civil investigue o crime e suspeita de execução. De acordo com a investigação, a execução aconteceu provavelmente por conta da um conflito entre grupos criminosos. </conteudo>\n",
      "</noticia_2>\n",
      "\n",
      "<noticia_3>\n",
      "\t<data>2021-06-16</data>\n",
      "\t<titulo>POÇOS DE CALDAS | Mais 77 casos e duas mortes confirmadas</titulo>\n",
      "\t<autor>ondapocos</autor>\n",
      "\t<link>https://ondapocos.com.br/pocos-de-caldas-mais-77-casos-e-duas-mortes-confirmadas/</link>\n",
      "\t<conteudo>Mais 77 casos e duas mortes foram confirmados em Poços de Caldas (MG), nesta quarta-feira (16), em boletim da prefeitura. As vítimas mais recentes são dois homens de 51 e 79 anos, respectivamente. A cidade soma 362 óbitos desde o início da pandemia. Poços tem 11.340 casos positivos, 9.642 recuperados. 1.217 pessoas seguem em isolamento domiciliar e 90 pacientes estão internados na UTI (17 em leitos não exclusivos pra Covid). Segundo a prefeitura, a faixa etária de maior incidência de casos é dos 30 a 39 anos, que corresponde a 22,07% dos casos. Vacinômetro 1ª dose: 50.687 pessoas receberam 2ª dose: 23.197 pessoas receberam </conteudo>\n",
      "</noticia_3>\n",
      "\n",
      "<noticia_4>\n",
      "\t<data>2022-07-28</data>\n",
      "\t<titulo>Mais 73 novos casos da covid são registrados em Poços de Caldas nesta quarta-feira</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/mais-73-novos-casos-da-covid-sao-registrados-em-pocos-de-caldas-nesta-quarta-feira/</link>\n",
      "\t<conteudo>Mais 73 novos casos da covid-19 foram registrados em Poços de Caldas nesta quarta-feira,27. Segundo os dados do painel, a cidade contabiliza 29.878 casos confirmados desde o início da pandemia. 793 pessoas estão isoladas em casa, duas internadas em ala e duas na UTI. Mais 57 pessoas se recuperaram da doença totalizando 28.493 casos recuperados. As mortes registradas desde o início da pandemia até o momento são 588. Nesta quarta-feira, foram aplicadas 1.330 doses de vacina contra a covid-19. </conteudo>\n",
      "</noticia_4>\n",
      "\n",
      "<noticia_5>\n",
      "\t<data>2020-04-05</data>\n",
      "\t<titulo>COVID-19: Poços de Caldas está com 262 casos suspeitos</titulo>\n",
      "\t<autor>ondapocos</autor>\n",
      "\t<link>https://ondapocos.com.br/covid-19-pocos-de-caldas-esta-com-262-casos-suspeitos/</link>\n",
      "\t<conteudo>O Informe Epidemiológico divulgado pela Secretaria de Estado da Saúde de Minas Gerais, atualizado neste domingo, 5, mostra que em Poços de Caldas, são 266 notificações do Novo Coronavírus – Covid 19. Destes, 262 são casos suspeitos, 2, descartados e 2 confirmados. A última atualização do informe mostra ainda que até o momento em Minas Gerais são 47.078 casos suspeitos para COVID-19 e 498 casos foram confirmados. Oitenta e quatro (84) óbitos estão em investigação e permanecem seis (6) óbitos confirmados.</conteudo>\n",
      "</noticia_5>\n",
      "\n",
      "<noticia_6>\n",
      "\t<data>2022-08-25</data>\n",
      "\t<titulo>Ocorrências de furto aumentam em 8,06% nos primeiros sete meses do ano em Poços</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/ocorrencias-de-furto-aumentam-em-806-nos-primeiros-sete-meses-do-ano-em-pocos/</link>\n",
      "\t<conteudo>As ocorrências de furto registradas em Poços de Caldas aumentaram em 8,06% nos primeiros sete meses de 2022. Os dados apurados pelo jornalismo da Onda Poços são da Secretaria de Estado de Justiça e Segurança Pública de Minas Gerais (Sejusp). De janeiro a julho deste ano foram registradas 1.891 ocorrências, já no mesmo período de 2021 foram registrados 1.750 casos. Os dados mostram ainda que, no ano de 2020 foram registrados 2.037 casos de furtos consumados na cidade, e no ano de 2021 foram 2.364 casos, um aumento de 16,05%. A Polícia Militar traz algumas orientações a população para a prevenção destes casos. Confira: </conteudo>\n",
      "</noticia_6>\n",
      "\n",
      "<noticia_7>\n",
      "\t<data>2020-03-26</data>\n",
      "\t<titulo>Poços está com 58 casos suspeitos de Covid-19; confira o último boletim</titulo>\n",
      "\t<autor>ondapocos</autor>\n",
      "\t<link>https://ondapocos.com.br/pocos-esta-com-58-casos-suspeitos-de-covid-19-confira-o-ultimo-boletim/</link>\n",
      "\t<conteudo>O Informe Epidemiológico divulgado pela Secretaria de Estado de Saúde de Minas Gerais, atualizado nesta quinta, 26, mostra que em Poços de Caldas, são 60 notificações. Destes, 58 são casos suspeitos, 1, descartado e 1 confirmado. O Informe mostra ainda, que no Estado de Minas Gerais, são 17.865 notificações, 17.409 casos suspeitos, 153 confirmados e 303 descartados. Até o momento não foi registrado óbito no Estado de Minas, por Coronavírus. Desde esta quarta, 25, a Secretaria Municipal de Saúde divulga o Informe Epidemiológico publicado pelo Estado. A alteração acompanha as mudanças adotadas também pela Secretaria de Estado de Saúde, considerando que o Ministério da Saúde classificou todo o país como transmissão comunitária, além da necessidade de qualificar as informações sobre a circulação do Coronavírus em Minas Gerais, o Boletim Informativo Diário COVID-19 passa a publicar o detalhamento apenas dos casos confirmados. A nomenclatura de casos monitorados não aparece mais no levantamento. O Estado informa número total de notificações e a divisão em casos suspeitos, casos confirmados e casos descartados. A cidade permanece com um caso importado confirmado. Na divulgação feita pela Vigilância Epidemiológica realizada até esta terça, 24, apareciam dois casos descartados: um, sendo o de uma mulher vinda da Lombardia na Itália, e o segundo, como sendo o de um homem que havia passado três semanas a trabalho em São Paulo. Ambos testaram negativo para o Novo Coronavírus – Covid 19. Na divulgação estadual, no entanto, apenas um descarte está computado por enquanto. O andamento da pandemia é extremamente dinâmico e estas orientações podem mudar de acordo com novas condutas recomendadas pelo Ministério da Saúde. A distribuição dos casos suspeitos por município, bem como de casos descartados e notificados, são atualizadas diariamente, através do site www.saude.mg.gov.br/coronavirus – “Distribuição dos casos de COVID-19 em Minas Gerais”.</conteudo>\n",
      "</noticia_7>\n",
      "\n",
      "<noticia_8>\n",
      "\t<data>2022-08-21</data>\n",
      "\t<titulo>Furto de veículos aumenta 25,87% nos primeiros sete meses do ano em Poços</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/furto-de-veiculos-aumenta-2587-nos-primeiros-sete-meses-do-ano-em-pocos/</link>\n",
      "\t<conteudo>O número de veículos furtados em Poços de Caldas teve um aumento de 25,87% nos primeiros sete meses deste ano. Os dados apurados pelo jornalismo da Onda Poços são da Secretaria de Estado de Justiça e Segurança Pública – Sejusp. Segundo a Sejusp, de janeiro a julho deste ano foram registrados 180 furtos de veículos na cidade. No mesmo período do ano passado foram registrados 143 casos. Esses casos já chegaram a registrar queda, mas em comparação entre 2020 e 2021. Os dados mostram que durante o ano de 2020 foram registrados 269 furtos de veículos. Em 2021 esse número sofreu uma queda, quando foram registrados 251 casos. Para prevenir que estes casos tendem a aumentar neste ano, a Polícia Militar traz algumas orientações a população: </conteudo>\n",
      "</noticia_8>\n",
      "\n",
      "<noticia_9>\n",
      "\t<data>2020-04-01</data>\n",
      "\t<titulo>Número de notificações de Covid-19 em Poços salta de 69 para 182 em 24 horas</titulo>\n",
      "\t<autor>ondapocos</autor>\n",
      "\t<link>https://ondapocos.com.br/numero-de-notificacoes-de-covid-19-em-pocos-salta-de-69-para-182-em-24-horas/</link>\n",
      "\t<conteudo>O Informe Epidemiológico divulgado pela Secretaria de Estado da Saúde de Minas Gerais, atualizado nesta quarta, 01, mostra que em Poços de Caldas, são 182 notificações do Novo Coronavírus – Covid 19, 113 a mais em comparação com o boletim divulgado ontem (31). Destes, 178 são casos suspeitos, 2, descartados e 2 confirmados. O Informe mostra ainda, que no Estado de Minas Gerais, são 34.799 notificações, 34.018 casos suspeitos, 314 confirmados e 464 descartados. Mais um óbito foi incluído nas estatísticas estaduais, como sendo o de um paciente de 44 anos, de Mariana, que não possuía comorbidade confirmada e faleceu em um hospital da capital. A segunda vítima por Covid-19 em Minas foi um homem de 66 anos, de Belo Horizonte, portador de cardiopatia e diabetes. Já o primeiro óbito por Covid-19 no Estado, foi de uma mulher de 82 anos, que estava em um hospital de Nova Lima, região metropolitana de Belo Horizonte, desde o dia 21 de março, com quadro de febre, tosse e desconforto respiratório. A paciente possuía doença cardiovascular crônica, diabetes e pneumopatia crônica.</conteudo>\n",
      "</noticia_9>```\n",
      "\n",
      "## CHAT HISTORY\n",
      "```Human: Olá. Tudo bem?\n",
      "AI: Olá! Tudo bem sim, obrigado por perguntar! Como posso ajudar você hoje?\n",
      "```\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Quais são as notícias mais recentes sobre acidentes em Poços de Caldas e região?`\n",
      "\n",
      "IA:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': '{\\n    \"resposta\": \"Foi registrado na tarde deste sábado um acidente de carro em Poços de Caldas. As primeiras informações são de que o acidente ocorreu na Avenida Leonor Furlaneto Delgado, mais conhecida como estrada da Cachoeirinha. A ocorrência segue em andamento.\",\\n    \"link\": \"https://ondapocos.com.br/acidente-e-registrado-em-pocos-de-caldas/\",\\n    \"data\": \"2022-06-26\",\\n    \"titulo\": \"Acidente é registrado em Poços de Caldas\",\\n    \"autor\": \"Aline Rodrigues\"\\n}',\n",
       " 'execution_id': '34a67c1f395f47a4933b98b0e59f60fd'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bot.execute(\"Pode me dar algumas notícias sobre acidentes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46636449-cf3c-48e7-8ada-9631dc1fe218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce vai receber uma pergunta de follow up do usuario, que pode nao ter muitos detalhes.\n",
      "O usuario quer realizar consultas na base de dados que contem noticias de Pocos de Caldas e regiao.\n",
      "Alguns usuarios costumam iniciar as conversas como uma saudacao, como `Ola. Tudo bem?`, por exemplo.\n",
      "Caso o `HUMAN INPUT` seja uma saudacao, faca apenas uma correcao ortografica. Caso contrário, REESCREVA a frase do `HUMAN INPUT` para que ela possa ser considerada uma pergunta independente. \n",
      "Inclua o maximo de detalhes possivel a partir do `CHAT HISTORY`, como contexto, data, titulo e autor da noticia.\n",
      "EM HIPÓTESE ALGUMA responda a pergunta em `HUMAN INPUT` ao usuário, APENAS REESCREVA A PERGUNTA.\n",
      "Sua resposta deve conter apenas a `HUMAN INPUT` reescrita.\n",
      "\n",
      "## CHAT HISTORY\n",
      "```Human: Olá. Tudo bem?\n",
      "AI: Olá! Tudo bem sim, obrigado por perguntar! Como posso ajudar você hoje?\n",
      "Human: Quais são as notícias mais recentes sobre acidentes em Poços de Caldas e região?\n",
      "AI: {\n",
      "    \"resposta\": \"Foi registrado na tarde deste sábado um acidente de carro em Poços de Caldas. As primeiras informações são de que o acidente ocorreu na Avenida Leonor Furlaneto Delgado, mais conhecida como estrada da Cachoeirinha. A ocorrência segue em andamento.\",\n",
      "    \"link\": \"https://ondapocos.com.br/acidente-e-registrado-em-pocos-de-caldas/\",\n",
      "    \"data\": \"2022-06-26\",\n",
      "    \"titulo\": \"Acidente é registrado em Poços de Caldas\",\n",
      "    \"autor\": \"Aline Rodrigues\"\n",
      "}\n",
      "```\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Acidentes de moto?`\n",
      "\n",
      "IA: A forma reescrita do `HUMAN INPUT` é \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-09 02:08:25.595\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m68\u001b[0m - \u001b[34m\u001b[1mPergunta original: Acidentes de moto?\u001b[0m\n",
      "\u001b[32m2024-01-09 02:08:25.596\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m69\u001b[0m - \u001b[34m\u001b[1mPergunta melhorada: Quais são as notícias mais recentes sobre acidentes de moto em Poços de Caldas e região?\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnalise a mensagem do usuario em \"HUMAN INPUT\" e o \"CHAT HISTORY\" e classifique a intencao de acordo com as seguintes categorias:\n",
      "\n",
      "- \"Inicio de conversa\": Saudacoes e cumprimentos do usuario, reconheca frases como \"oi\", \"ola\", \"bom dia\", \"tudo bem:\", etc.\n",
      "- \"Consulta de conteudo\": Perguntas sobre noticias da base de dados, reconheca trechos como \"quais sao as ultimas noticias\", \"o que foi reportado no bairro\", etc.\n",
      "- \"\": QUALQUER PERGUNTA QUE NAO SE ENCAIXE NAS CATEGORIAS ACIMA, ou que nao possa ser respondida com o contexto disponivel na base de dados, a qual contem noticias de Pocos de Caldas e regiao.\n",
      "\n",
      "Escolha apenas uma das opcoes. Sua resposta deve conter APENAS a categoria.\n",
      "\n",
      "## CHAT HISTORY\n",
      "```Human: Olá. Tudo bem?\n",
      "AI: Olá! Tudo bem sim, obrigado por perguntar! Como posso ajudar você hoje?\n",
      "Human: Quais são as notícias mais recentes sobre acidentes em Poços de Caldas e região?\n",
      "AI: {\n",
      "    \"resposta\": \"Foi registrado na tarde deste sábado um acidente de carro em Poços de Caldas. As primeiras informações são de que o acidente ocorreu na Avenida Leonor Furlaneto Delgado, mais conhecida como estrada da Cachoeirinha. A ocorrência segue em andamento.\",\n",
      "    \"link\": \"https://ondapocos.com.br/acidente-e-registrado-em-pocos-de-caldas/\",\n",
      "    \"data\": \"2022-06-26\",\n",
      "    \"titulo\": \"Acidente é registrado em Poços de Caldas\",\n",
      "    \"autor\": \"Aline Rodrigues\"\n",
      "}\n",
      "```\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Quais são as notícias mais recentes sobre acidentes de moto em Poços de Caldas e região?`\n",
      "\n",
      "IA:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-09 02:08:26.513\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mexecute\u001b[0m:\u001b[36m72\u001b[0m - \u001b[34m\u001b[1mIntenção: Consulta de conteúdo\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce e um chatbot que responde sobre noticias da cidade de Pocos de Caldas.\n",
      "\n",
      "Sua tarefa e responder a mensagem do usuário em HUMAN INPUT utilizando o CONTEXTO providenciado.\n",
      "Considere o CHAT HISTORY.\n",
      "Nao responda nada que nao esteja no contexto. Se o contexto nao tiver informacoes relevantes a pergunta do usuario, responda \"nao sei\".\n",
      "Nao considere nenhuma noticia que nao seja de Pocos de Caldas.\n",
      "\n",
      "Formate sua resposta como um JSON conforme indicado abaxo:\n",
      "{\n",
      "    \"resposta\": \"sua resposta aqui\",\n",
      "    \"link\": \"link da noticia que voce usou para elaborar sua resposta\",\n",
      "    \"data\": \"data da noticia\",\n",
      "    \"titulo\": \"titulo da noticia\",\n",
      "    \"autor\": \"autor da noticia\"\n",
      "}\n",
      "Nao responda nada alem do JSON.\n",
      "\n",
      "## CONTEXTO\n",
      "```\n",
      "<noticia_1>\n",
      "\t<data>2022-09-22</data>\n",
      "\t<titulo>É falsa informação sobre assassinato de três ladrões de motos em Poços de Caldas</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/e-falsa-informacao-sobre-assassinato-de-tres-ladroes-de-motos-em-pocos-de-caldas/</link>\n",
      "\t<conteudo>Circula pelas redes sociais e aplicativos de conversa, um vídeo com informações de que três ladrões de motos foram executados em Poços de Caldas. Mas de acordo com apuração feita pelo jornalismo da Onda Poços junto à polícia, as informações são falsas. O crime, na verdade, foi registrado na cidade de Americana-SP, onde três homens foram encontrados com mãos e pés amarrados e com marcas de tiro às margens da Rodovia Ivo Macris, na manhã de quarta-feira (14). A Polícia Civil investigue o crime e suspeita de execução. De acordo com a investigação, a execução aconteceu provavelmente por conta da um conflito entre grupos criminosos. </conteudo>\n",
      "</noticia_1>\n",
      "\n",
      "<noticia_2>\n",
      "\t<data>2023-05-18</data>\n",
      "\t<titulo>VÍDEO | Motorista avança sinal vermelho, provoca acidente e foge pela contramão em Poços</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/video-motorista-avanca-sinal-vermelho-provoca-acidente-e-foge-pela-contramao-em-pocos/</link>\n",
      "\t<conteudo>A Polícia Civil investiga um acidente entre um motociclista e o condutor de um carro, ocorrido em Poços de Caldas. O acidente ocorreu no fim da noite do sábado,13, na área central da cidade. As imagens do acidente foram divulgadas nas redes sociais nesta quarta-feira,17. Em nota ao jornalismo da Onda Poços, a Polícia Civil informou que, o motociclista relatou que seguia pela Rua Marechal Deodoro em linha reta, e que ao passar pelo cruzamento com a Rua Corrêa Neto, atingiu um veículo VW/Gol de cor prata que avançou o sinal vermelho. A Polícia Civil informou que, instaurou Inquérito Policial para apurar as circunstâncias e as causas do acidente e que os trabalhos investigativos prosseguem visando identificar e localizar o condutor do veículo.</conteudo>\n",
      "</noticia_2>\n",
      "\n",
      "<noticia_3>\n",
      "\t<data>2022-08-21</data>\n",
      "\t<titulo>Furto de veículos aumenta 25,87% nos primeiros sete meses do ano em Poços</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/furto-de-veiculos-aumenta-2587-nos-primeiros-sete-meses-do-ano-em-pocos/</link>\n",
      "\t<conteudo>O número de veículos furtados em Poços de Caldas teve um aumento de 25,87% nos primeiros sete meses deste ano. Os dados apurados pelo jornalismo da Onda Poços são da Secretaria de Estado de Justiça e Segurança Pública – Sejusp. Segundo a Sejusp, de janeiro a julho deste ano foram registrados 180 furtos de veículos na cidade. No mesmo período do ano passado foram registrados 143 casos. Esses casos já chegaram a registrar queda, mas em comparação entre 2020 e 2021. Os dados mostram que durante o ano de 2020 foram registrados 269 furtos de veículos. Em 2021 esse número sofreu uma queda, quando foram registrados 251 casos. Para prevenir que estes casos tendem a aumentar neste ano, a Polícia Militar traz algumas orientações a população: </conteudo>\n",
      "</noticia_3>\n",
      "\n",
      "<noticia_4>\n",
      "\t<data>2022-08-26</data>\n",
      "\t<titulo>Motos furtadas são encontradas na zona Leste de Poços de Caldas</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/motos-furtadas-sao-encontradas-na-zona-leste-de-pocos-de-caldas/</link>\n",
      "\t<conteudo>Duas motos furtadas em Poços de Caldas nos últimos dias, foram localizadas nesta sexta-feira, 26, em um terreno na região Leste da cidade. A PM informou que recebeu ligação de um agricultor que viu as motocicletas em um terreno próximo a chácaras no bairro Estância Poços de Caldas. Ao consultar o sistema informatizado, a polícia constatou que as motos possuíam queixa de furto. Uma delas, ainda conforme a PM, foi pintada de cor preta. Os veículos foram removidos. </conteudo>\n",
      "</noticia_4>\n",
      "\n",
      "<noticia_5>\n",
      "\t<data>2023-07-12</data>\n",
      "\t<titulo>Câmera de monitoramento flagra acidente entre carro e moto em Poços de Caldas</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/camera-de-monitoramento-flagra-acidente-entre-carro-e-moto-em-pocos-de-caldas/</link>\n",
      "\t<conteudo>Uma câmera de monitoramento registrou um acidente entre um carro e uma moto em Poços de Caldas, na noite da última terça-feira (11). Pelas imagens (veja no final da notícia), é possível observar o momento da colisão. A moto seguia pela Avenida Vereador Edmundo Cardillo no sentido bairro-centro, quando, no trevo de acesso ao bairro Bianucci, um carro avançou o sinal de pare, ocasionando a colisão. Dois jovens estavam na moto, um condutor de 19 anos e uma mulher de 18 anos. Segundo informações da Polícia Militar, ambos sofreram ferimentos leves. O motorista do carro, de 53 anos, não se machucou. Ele relatou aos policiais que, ao atravessar o trevo, a motocicleta colidiu lateralmente com seu veículo. Ainda conforme a PM, a motocicleta foi removida por infração de trânsito, e o condutor não possuía Carteira Nacional de Habilitação (CNH). O trecho onde ocorreu o acidente, mesmo possuindo radar de fiscalização eletrônica, frequentemente registra ocorrências de acidentes, sendo a maioria deles envolvendo colisões entre motos e carros.</conteudo>\n",
      "</noticia_5>\n",
      "\n",
      "<noticia_6>\n",
      "\t<data>2021-12-06</data>\n",
      "\t<titulo>Em uma hora, dois acidentes são registrados na Rodovia do Contorno em Poços de Caldas</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/em-uma-hora-dois-acidentes-sao-registrados-na-rodovia-do-contorno-em-pocos-de-caldas/</link>\n",
      "\t<conteudo>Dois acidentes foram registrados na tarde deste domingo,05, na Rodovia do Contorno em Poços de Caldas. Segundo a Polícia Militar Rodoviária, o primeiro acidente foi por volta de 16h entre dois carros, dois corsas. Um motorista contou que seguia sentido decrescente da via quando ao passar por um sonorizador, perdeu o controle da direção, invadiu a pista contrária e colidiu contra o outro carro. Ainda segundo o motorista, estava chovendo no momento. O outro condutor, disse que viu um carro desgovernado invadindo a sua mão de direção o que resultou na colisão. Os bombeiros e Samu também foram acionados. Em um dos carros haviam cinco ocupantes, três deles foram conduzidos para o hospital pela Unidade de Resgate dos Bombeiros e também por uma equipe do Samu, todos com ferimentos leves. Ainda segundo os Bombeiros, o único ocupante do outro carro, não se feriu. Segundo a Polícia Militar Rodoviária, nenhum crime ou infração de trânsito foi constatado. Por volta de 16h59, outro acidente foi registrado na mesma Rodovia, este, foi entre duas caminhonetes. Segundo a Polícia Militar Rodoviária, o motorista da caminhonete I/CHEV TRACKER, disse que seguia sentido crescente da via, quando o motorista de uma caminhonete fiat/strada realizou uma manobra de ultrapassagem e perdeu o controle da direção, atingindo a traseira da camioneta e rodando na pista. Aos policiais, o condutor da Fiat/Strada confirmou que perdeu o controle da direção. Os dois motoristas informaram que chovia no momento do acidente. Ambos foram submetidos ao teste do etilômetro que constatou que o motorista da Fiat /Strada havia ingerido bebida alcoólica.   Os veículos foram retirados do local por acionamento de serviço remoção particular. Os Bombeiros também foram acionados, nos veículos estavam apenas os motoristas. Ambos foram sofreram lesões superficiais. Um deles, recusou atendimento. Já o outro foi levado ao Hospital com um corte no supercílio.   De acordo com a Polícia Militar Rodoviária, foi aplicado o Auto de Infração de Trânsito ao motorista da Fiat/Strada. </conteudo>\n",
      "</noticia_6>\n",
      "\n",
      "<noticia_7>\n",
      "\t<data>2021-10-25</data>\n",
      "\t<titulo>Mais um acidente: motoentregador bate em carro no centro de Poços</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/mais-um-acidente-motoentregador-bate-em-carro-no-centro-de-pocos/</link>\n",
      "\t<conteudo>Mais um acidente de trânsito foi registrado em Poços de Caldas nesta segunda-feira (25). Um motoentregador ficou ferido depois de bater contra um carro na Rua Rio Grande do Sul, centro da cidade, por volta das 14h30. Segundo informações do Demutran, que atendeu a ocorrência, o motorista do carro disse que a colisão aconteceu no momento em que ele deu seta para entrar em uma vaga, não sendo possível evitar o acidente. O condutor da moto, com o impacto da batida, foi arremessado por alguns metros. Ele foi socorrido pelo Samu e encaminhado para atendimento médico com ferimentos pelo corpo aparentemente leves. Pela manhã, outros dois acidentes foram registrados na cidade, sendo um deles também na área central e outro na saída oeste do município, na divisa entre Minas e São Paulo. </conteudo>\n",
      "</noticia_7>\n",
      "\n",
      "<noticia_8>\n",
      "\t<data>2022-05-27</data>\n",
      "\t<titulo>Motociclista fica ferido em acidente na região sul de Poços de Caldas</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/motociclista-fica-ferido-em-acidente-na-regiao-sul-de-pocos-de-caldas/</link>\n",
      "\t<conteudo>Um acidente foi registrado na manhã desta sexta-feira,27, em Poços de Caldas. Um motociclista ficou ferido após uma colisão com uma carreta. O acidente ocorreu na Avenida Alcoa, na região sul da cidade. As primeiras informações da Polícia, são de que, a carreta foi realizar a conversão à direita para entrar em uma empresa e a moto seguia sentido bairro, momento em que houve a colisão. Uma equipe do Samu foi acionada e prestou atendimento ao motociclista. A Polícia Militar também foi acionada e registrou a ocorrência. Segundo o Samu, o motociclista foi socorrido consciente, e há suspeita de fratura no punho. A vítima foi encaminhada ao Hospital Santa Casa. </conteudo>\n",
      "</noticia_8>```\n",
      "\n",
      "## CHAT HISTORY\n",
      "```Human: Olá. Tudo bem?\n",
      "AI: Olá! Tudo bem sim, obrigado por perguntar! Como posso ajudar você hoje?\n",
      "Human: Quais são as notícias mais recentes sobre acidentes em Poços de Caldas e região?\n",
      "AI: {\n",
      "    \"resposta\": \"Foi registrado na tarde deste sábado um acidente de carro em Poços de Caldas. As primeiras informações são de que o acidente ocorreu na Avenida Leonor Furlaneto Delgado, mais conhecida como estrada da Cachoeirinha. A ocorrência segue em andamento.\",\n",
      "    \"link\": \"https://ondapocos.com.br/acidente-e-registrado-em-pocos-de-caldas/\",\n",
      "    \"data\": \"2022-06-26\",\n",
      "    \"titulo\": \"Acidente é registrado em Poços de Caldas\",\n",
      "    \"autor\": \"Aline Rodrigues\"\n",
      "}\n",
      "```\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Quais são as notícias mais recentes sobre acidentes de moto em Poços de Caldas e região?`\n",
      "\n",
      "IA:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': '{\\n    \"resposta\": \"Foi registrado um acidente de moto na região sul de Poços de Caldas. Um motociclista ficou ferido após uma colisão com uma carreta. O acidente ocorreu na Avenida Alcoa. O motociclista foi socorrido pelo Samu e encaminhado ao Hospital Santa Casa.\",\\n    \"link\": \"https://ondapocos.com.br/motociclista-fica-ferido-em-acidente-na-regiao-sul-de-pocos-de-caldas/\",\\n    \"data\": \"2022-05-27\",\\n    \"titulo\": \"Motociclista fica ferido em acidente na região sul de Poços de Caldas\",\\n    \"autor\": \"Aline Rodrigues\"\\n}',\n",
       " 'execution_id': '741bb7fbc73242488d592ab0b24360fa'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bot.execute(\"Acidentes de moto?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d2a075-fb54-4cf9-9de0-94cb8fd98823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Optional\n",
    "# from datetime import date\n",
    "# from uuid import UUID, uuid4\n",
    "# from abc import ABC, abstractmethod\n",
    "\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# class BaseDocument(ABC, BaseModel):\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def repr(self) -> str:\n",
    "#         pass\n",
    "\n",
    "\n",
    "# class News(BaseDocument):\n",
    "#     id: UUID\n",
    "#     title: str\n",
    "#     document: str\n",
    "#     date: date\n",
    "#     link: str\n",
    "#     author: Optional[str] = None\n",
    "#     categories: Optional[List[str]] = None\n",
    "#     snippet: Optional[str] = None\n",
    "#     thumbnail_alt: Optional[str] = None\n",
    "#     thumbnail_link: Optional[str] = None\n",
    "\n",
    "#     def repr(self, order: Optional[int] = None):\n",
    "#         _start_char = \"\\t\" if order else \"\"\n",
    "#         _firstline = f\"\\n<noticia_{order}>\\n\" if order else \"\"\n",
    "#         _lastline = f\"</noticia_{order}>\" if order else \"\"\n",
    "#         return (\n",
    "#         f\"{_firstline}\"\n",
    "#         f\"{_start_char}<data>{self.date}</data>\\n\"\n",
    "#         f\"{_start_char}<titulo>{self.title}</titulo>\\n\"\n",
    "#         f\"{_start_char}<autor>{self.author}</autor>\\n\"\n",
    "#         f\"{_start_char}<link>{self.link}</link>\\n\"\n",
    "#         f\"{_start_char}<conteudo>{self.document}</conteudo>\\n\"\n",
    "#         f\"{_lastline}\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# class VectorDatabaseNewsResult(BaseDocument):\n",
    "#     distance: float\n",
    "#     news: News\n",
    "\n",
    "#     def repr(self):\n",
    "#         return repr(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7c9277-9c26-4191-b304-2c9398b7ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news = News(\n",
    "#     id=uuid4(),\n",
    "#     title=\"Noticia teste\",\n",
    "#     document=\"Esse é o conteúdo de uma notícia teste\",\n",
    "#     date=\"2023-01-01\",\n",
    "#     link=\"www.com.br\",\n",
    "# )\n",
    "\n",
    "# print(news.repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1bc743f-6c26-4567-a708-d28664398545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "There was a problem when trying to write in your cache folder (/home/jovyan/.cache/huggingface/hub). You should set the environment variable TRANSFORMERS_CACHE to a writable directory.\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/configuration_utils.py:387: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce vai receber uma pergunta de follow up do usuario, que pode nao ter muitos detalhes.\n",
      "O usuario quer realizar consultas na base de dados que contem noticias de Pocos de Caldas e regiao.\n",
      "Alguns usuarios costumam iniciar as conversas como uma saudacao, como `Ola. Tudo bem?`, por exemplo.\n",
      "Caso o `HUMAN INPUT` seja uma saudacao, faca apenas uma correcao ortografica. Caso contrário, REESCREVA a frase do `HUMAN INPUT` para que ela possa ser considerada uma pergunta independente. \n",
      "Inclua o maximo de detalhes possivel a partir do `CHAT HISTORY`, como contexto, data, titulo e autor da noticia.\n",
      "EM HIPÓTESE ALGUMA responda a pergunta em `HUMAN INPUT` ao usuário, APENAS REESCREVA A PERGUNTA.\n",
      "Sua resposta deve conter apenas a `HUMAN INPUT` reescrita.\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Olá`\n",
      "\n",
      "IA: A forma reescrita do `HUMAN INPUT` é \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Olá. Tudo bem?\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory, ChatMessageHistory\n",
    "\n",
    "from bot import BotConfig\n",
    "from bot.vector_databases import get_vector_database\n",
    "from bot.handlers import PrivateHandler, StandaloneHandler, IntentionHandler, QueryHandler\n",
    "\n",
    "config = BotConfig()\n",
    "\n",
    "vdb = get_vector_database(\"chroma\")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chat_history=ChatMessageHistory(),\n",
    "            return_messages=True,\n",
    "            memory_key=\"chat_history\",\n",
    "            input_key=\"human_input\",\n",
    "            human_prefix=config.HUMAN_PREFIX,\n",
    "            ai_prefix=config.AI_PREFIX,\n",
    "        )\n",
    "\n",
    "standalone_handler = StandaloneHandler(llm_model=config.LLM_MODEL_NAME, memory=memory, verbose=True)\n",
    "\n",
    "intention_handler = IntentionHandler(llm_model=config.LLM_MODEL_NAME, memory=memory, verbose=False)\n",
    "\n",
    "message = \"Olá\"\n",
    "\n",
    "improved_message = standalone_handler.predict(message)\n",
    "\n",
    "intention = intention_handler.predict(improved_message)\n",
    "\n",
    "if intention == 'Inicio de conversa':\n",
    "    print(improved_message)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a13b915-6461-478b-bdec-dcbae9eaea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce vai receber uma pergunta de follow up do usuario, que pode nao ter muitos detalhes.\n",
      "O usuario quer realizar consultas na base de dados que contem noticias de Pocos de Caldas e regiao.\n",
      "Alguns usuarios costumam iniciar as conversas como uma saudacao, como `Ola. Tudo bem?`, por exemplo.\n",
      "Caso o `HUMAN INPUT` seja uma saudacao, faca apenas uma correcao ortografica. Caso contrário, REESCREVA a frase do `HUMAN INPUT` para que ela possa ser considerada uma pergunta independente. \n",
      "Inclua o maximo de detalhes possivel a partir do `CHAT HISTORY`, como contexto, data, titulo e autor da noticia.\n",
      "EM HIPÓTESE ALGUMA responda a pergunta em `HUMAN INPUT` ao usuário, APENAS REESCREVA A PERGUNTA.\n",
      "Sua resposta deve conter apenas a `HUMAN INPUT` reescrita.\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Qual foi a notícia de acidente de moto mais antiga?`\n",
      "\n",
      "IA: A forma reescrita do `HUMAN INPUT` é \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce e um chatbot que responde sobre noticias da cidade de Pocos de Caldas.\n",
      "\n",
      "Sua tarefa e responder a mensagem do usuário em HUMAN INPUT utilizando o CONTEXTO providenciado.\n",
      "Considere o CHAT HISTORY.\n",
      "Nao responda nada que nao esteja no contexto. Se o contexto nao tiver informacoes relevantes a pergunta do usuario, responda \"nao sei\".\n",
      "Nao considere nenhuma noticia que nao seja de Pocos de Caldas.\n",
      "\n",
      "Formate sua resposta como um JSON conforme indicado abaxo:\n",
      "{\n",
      "    \"resposta\": \"sua resposta aqui\",\n",
      "    \"link\": \"link da noticia que voce usou para elaborar sua resposta\",\n",
      "    \"data\": \"data da noticia\",\n",
      "    \"titulo\": \"titulo da noticia\",\n",
      "    \"autor\": \"autor da noticia\"\n",
      "}\n",
      "Nao responda nada alem do JSON.\n",
      "\n",
      "## CONTEXTO\n",
      "```\n",
      "<noticia_1>\n",
      "\t<data>2022-10-09</data>\n",
      "\t<titulo>Sobe para seis o número de mortos de acidente registrado neste domingo (9)</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/sobe-para-seis-o-numero-de-mortos-de-acidente-registrado-neste-domingo-9/</link>\n",
      "\t<conteudo>Subiu para seis o número de mortos em um acidente entre dois carros registrado próximo a São João da Boa Vista (SP), cidade que fica a menos de 60 km de Poços de Caldas, na manhã deste domingo (9). Segundo a concessionária Renovias, o acidente aconteceu por volta das 5h30 no km 226 da Rodovia Dom Tomás Vaquero (SP-344), que liga a cidade a Vargem Grande do Sul. De acordo com a Polícia Rodoviária, uma caminhonete bateu na traseira do carro em que estavam os seis ocupantes. O veículo, modelo Parati, foi arrastado por cerca de 200 metros e pegou fogo em seguida. A polícia informou que cinco passageiros do veículo atingido morreram carbonizados. Uma sexta vítima foi socorrida em estado gravíssimo para o Pronto-Socorro da Santa Casa de São João da Boa Vista, mas não resistiu aos ferimentos. Todas eram da mesma família, segundo informado. O motorista da caminhonete, cuja identidade não foi divulgada, sofreu ferimentos leves e foi socorrido para Santa Casa. Depois, ele foi encaminhado para um hospital particular. Segundo a Polícia Civil, ele deverá ficar preso e passará por audiência de custódia na segunda-feira (10). </conteudo>\n",
      "</noticia_1>\n",
      "\n",
      "<noticia_2>\n",
      "\t<data>2022-11-11</data>\n",
      "\t<titulo>Vídeo: Defesa Social esclarece acidente que resultou em vítima grave em Poços de Caldas-MG</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/video-defesa-social-esclarece-acidente-que-resultou-em-vitima-grave-em-pocos-de-caldas-mg/</link>\n",
      "\t<conteudo>A secretaria de Defesa Social de Poços de Caldas, esclareceu nesta sexta-feira, 11, informações sobre o acidente registrado na cidade, que resultou em uma vítima grave. O acidente aconteceu no último sábado, 5, na Rua Oswaldo Cruz, no Bairro Santa Rita, que recentemente sofreu alteração no trânsito, passando de mão dupla para mão única no sentido bairro-centro. O piloto de uma moto perdeu o controle da direção e bateu contra um poste de iluminação pública. Uma jovem, de 15 anos, que estava na garupa, ficou gravemente ferida. Durante entrevista ao programa Onda In Foco, o secretário de Defesa Social, Rafael Tadeu Conde Maria, informou que de acordo com informações do Boletim de Ocorrência, a alteração feita no sentido da via não foi o motivo do acidente e sim o excesso de velocidade. Imagens obtidas pela Onda Poços, mostram o momento em que o condutor da moto perde o controle após uma curva, antes do veículo atingir o poste. Ainda conforme registro policial, confirmado pelo secretário, a jovem estava sem capacete e o piloto da moto era inabilitado. Ao jornalismo da Onda, um irmão da vítima, informou que ela estava de capacete no momento do acidente, mas que o equipamento de proteção foi retirado do local antes da chegada da polícia por uma terceira pessoa, proprietária da moto, que compareceu ao local após o ocorrido. A garota, segundo a Santa Casa da cidade, continua internada em estado gravíssimo. Ela sofreu traumatismo craniano. </conteudo>\n",
      "</noticia_2>\n",
      "\n",
      "<noticia_3>\n",
      "\t<data>2023-02-16</data>\n",
      "\t<titulo>Carreta com 14 toneladas de laticínios tomba na Rodovia SP-342 em Águas da Prata</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/carreta-com-14-toneladas-de-laticinios-tomba-na-rodovia-sp-342-em-aguas-da-prata/</link>\n",
      "\t<conteudo>Um acidente envolvendo uma carreta foi registrado na noite desta quarta-feira,15, em Águas da Prata. A assessoria de comunicação da Renovias, empresa que administra a Rodovia SP-342, informou ao jornalismo da Onda Poços que, a concessionária foi acionada por volta das 22h28 para atender uma ocorrência de acidente no KM 246, da Serra de Águas da Prata. Ainda segundo a Renovias, a carreta carregada com 14 toneladas de laticínios tombou na faixa oeste, na pista simples. O motorista foi socorrido com ferimentos leves pela equipe da Renovias, para UPA de São João da Boa Vista. A pista oeste teve que ser interditada e o desvio pelo acostamento e pela faixa leste. Na manhã desta quinta-feira,16, a pista oeste permanece interditada e a equipe da Renovias está no local e aguarda a remoção do veículo e da carga.</conteudo>\n",
      "</noticia_3>\n",
      "\n",
      "<noticia_4>\n",
      "\t<data>2021-10-28</data>\n",
      "\t<titulo>CURIOSIDADE | News of the World, 6º álbum do Queen completa 44 anos de lançamento</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/curiosidade-news-of-the-world-6o-album-do-queen-completa-44-anos-de-lancamento/</link>\n",
      "\t<conteudo>Em 28 de outubro de 1977 era lançando ‘News of the world’, o sexto álbum da banda Queen. Com 11 músicas, entre elas os grandes sucessos; We Will Rock You, We are the champions e Spread Your Wings, o álbum ganhou a quádrupla platina nos Estados Unidos, dupla no Reino Unido outras altas posições no mundo. Para falar um pouco sobre o álbum com hits que fazem parte da programação da Onda Poços, o jornalismo da emissora conversou com o produtor musical Rodrigo Lee. Rodrigo comenta que a banda vinha de dois discos inspirados; A Night at The Opera e A Day at The Races, com isso a responsabilidade perante crítica e público era enorme. “Na realidade eles não superaram a criatividade e relevância dos álbuns anteriores, mas conseguiram chegar a um público fora do meio do Rock n’ Roll, pois dois dos sucessos de ‘News of The World‘ (We Will Rock You e We Are The Champions) são, desde 1977, tocados nos mais diversos eventos populares ao redor do mundo. Produzido pela própria banda o bom disco ‘News of The World’ é recheado de grandes músicas como: Spread Your Wings, It’s Late, Who Needs You e Sheer Heart Attack, entre outras”, analisa. We Will Rock You ganhou o mundo sendo tocada em arenas de esporte e estádios. A ideia de ter uma música simples com pisada, pisada, palma e pausa duas vezes, partiu de May, assim o público poderia se envolver diretamente no show. Freddie Mercury havia contado que We are The Champions foi escrita em 1975, porém, gravada apenas em 1977. A canção conquistou o segundo lugar no Reino Unido e quarto nos Estados Unidos. Como as quintas-feiras têm sido usadas para relembrar alguns momentos, neste dia, relembremos estes sucessos. </conteudo>\n",
      "</noticia_4>\n",
      "\n",
      "<noticia_5>\n",
      "\t<data>2022-10-10</data>\n",
      "\t<titulo>1ª morte por varíola dos macacos é confirmada no Sul de Minas</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/1a-morte-por-variola-dos-macacos-e-confirmada-no-sul-de-minas/</link>\n",
      "\t<conteudo>A primeira morte por varíola dos macacos foi confirmada no Sul de Minas Gerais, neste domingo,09. A Prefeitura de Pouso Alegre confirmou que se tratava de um rapaz de 21 anos, com comorbidades, que estava internado desde 11 de setembro. Esta é a segunda morte registrada no estado de Minas Gerais. O primeiro caso foi de um homem de 41 anos que estava internado em Belo Horizonte. Doença no Brasil De acordo com boletim divulgado pelo Ministério da Saúde na sexta-feira (7), até o momento, há 8.340 casos confirmados de varíola dos macacos no Brasil. Outros 4.586 estão em acompanhamento. O estado de São Paulo reúne o maior número de casos (3.843), seguido por Rio de Janeiro (1.120) e Minas Gerais (514). Com a morte informada neste domingo, o país já registra dois óbitos em Minhas Gerais e outros dois no Rio de Janeiro. Transmissão Conhecida internacionalmente como monkeypox, a varíola dos macacos é uma doença causada por vírus e transmitida pelo contato próximo ou íntimo com uma pessoa infectada e com lesões de pele. O contato pode se dar por meio de um abraço, beijo, massagens, relações sexuais ou secreções respiratórias. A transmissão também ocorre por contato com objetos, tecidos (roupas, roupas de cama ou toalhas) e superfícies que foram utilizadas pelo doente. Vacina Segundo o Ministério da Saúde, já está no Brasil o primeiro lote importado de vacinas contra a monkeypox. A remessa de 9,8 mil doses desembarcou na terça-feira passada (4) no Aeroporto de Guarulhos (SP). Cerca de 50 mil doses foram compradas pelo governo via fundo rotatório da Organização Pan-americana da Saúde (Opas). Os próximos lotes estão previstos para serem entregues até o fim de 2022. * Com informações de Agência Brasil </conteudo>\n",
      "</noticia_5>\n",
      "\n",
      "<noticia_6>\n",
      "\t<data>2023-04-18</data>\n",
      "\t<titulo>Polícia Civil apreende moto usada por homem que quase atropelou pedestres em Poços</titulo>\n",
      "\t<autor>Matheus Luis</autor>\n",
      "\t<link>https://ondapocos.com.br/policia-civil-apreende-moto-usada-por-homem-que-quase-atropelou-pedestres-em-pocos/</link>\n",
      "\t<conteudo>A Polícia Civil apreendeu nesta terça-feira,18, em Poços de Caldas, a motocicleta usada por homem que quase atropelou pedestres e um cão, no mês passado, ao praticar manobras perigosas. Nesta terça, a Polícia Civil deu cumprimento ao mandado de busca e apreensão na Rua Leonor Furlaneto Delgado, no bairro Jardim Philadélfia, onde foi apreendida uma motocicleta da marca Honda, modelo CG 160 Start, cor cinza, ano/modelo 2021, veículo usado pelo homem que praticou manobras perigosas. Relembre o caso Em março deste ano, o condutor foi flagrado realizando manobras perigosas na Rua Maracanã, no bairro Dom Bosco, na ocasião, ele perdeu o controle da direção da morto e quase atropelou duas pessoas que se encontravam na calçada, sendo uma delas criança, além de um cachorro. Segundo a Polícia Civil, o veículo, além das autuações de infração de trânsito que foram registradas por ocasião do fato, foi removido ao pátio credenciado pelo DETRAN-MG, sendo apreendido nos autos do inquérito policial instaurado para se apurar os crimes capitulados nos artigos 308, 309 e 311 do Código de Trânsito brasileiro.  </conteudo>\n",
      "</noticia_6>```\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Qual foi a notícia de acidente de moto mais antiga?`\n",
      "\n",
      "IA:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n    \"resposta\": \"A notícia mais antiga de acidente de moto é sobre o acidente registrado na cidade de Poços de Caldas, onde um homem quase atropelou pedestres ao praticar manobras perigosas.\",\\n    \"link\": \"https://ondapocos.com.br/policia-civil-apreende-moto-usada-por-homem-que-quase-atropelou-pedestres-em-pocos/\",\\n    \"data\": \"2023-04-18\",\\n    \"titulo\": \"Polícia Civil apreende moto usada por homem que quase atropelou pedestres em Poços\",\\n    \"autor\": \"Matheus Luis\"\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Qual foi a notícia de acidente de moto mais antiga?\"\n",
    "\n",
    "improved_query = standalone_handler.predict(query)\n",
    "\n",
    "query_handler = QueryHandler(llm_model=config.LLM_MODEL_NAME, memory=memory, vector_database=vdb, verbose=True)\n",
    "\n",
    "context = query_handler.get_context(improved_query)\n",
    "\n",
    "query_handler.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d7f75-64e6-4f99-8ded-4ee1b067cd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a94f1-4b81-4529-befc-c94813ec8415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87901c78-fc94-486a-94a4-bf1feddc239d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f62dc2-b6af-4e18-9320-a4406b9d1f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce e um chatbot que responde sobre noticias da cidade de Pocos de Caldas.\n",
      "\n",
      "Sua tarefa e responder a mensagem do usuário em HUMAN INPUT utilizando o CONTEXTO providenciado.\n",
      "Considere o CHAT HISTORY.\n",
      "Nao responda nada que nao esteja no contexto. Se o contexto nao tiver informacoes relevantes a pergunta do usuario, responda \"nao sei\".\n",
      "Nao considere nenhuma noticia que nao seja de Pocos de Caldas.\n",
      "\n",
      "Formate sua resposta como um JSON conforme indicado abaxo:\n",
      "{\n",
      "    \"resposta\": \"sua resposta aqui\",\n",
      "    \"link\": \"link da noticia que voce usou para elaborar sua resposta\",\n",
      "    \"data\": \"data da noticia\",\n",
      "    \"titulo\": \"titulo da noticia\",\n",
      "    \"autor\": \"autor da noticia\"\n",
      "}\n",
      "Nao responda nada alem do JSON.\n",
      "\n",
      "## CONTEXTO\n",
      "```\n",
      "<noticia_1>\n",
      "\t<data>2021-08-17</data>\n",
      "\t<titulo>CURIOSIDADE| Sweet Child O’ Mine completa 33 anos de lançamento</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/curiosidade-sweet-child-o-mine-completa-33-anos-de-lancamento/</link>\n",
      "\t<conteudo>O hit que com certeza você já deve ter escutado em algum momento da sua vida completa 33 anos de lançamento, estamos falando de Sweet Child O’ Mine da banda Guns N’ Roses. A música que fez tanto sucesso em disco de vinil, fitas, cd’s, também é aclamada na internet com muitas visualizações. Sweet Child O’ Mine foi gravada em 1987 e lançada em agosto de 1988 como terceira faixa do albúm Appetite for Destruction, divulgado em julho de 1987. A canção faz parte da programação da Onda Poços. A música tem o dom de influenciar na vida das pessoas, e no caso da Sweet Child O’ mine, não poderia ser diferente. Em Poços de Caldas, o geógrafo Gustavo Lopes que é um Guns maníaco conta que começou a gostar de rock, por meio desta música. “O Guns entrou na minha vida quando eu tinha exatamente 9 anos. Meu irmão comprou o álbum Appetite for destruction e ele ouvia no quarto dele, eu escutava atrás da porta no começo. Comecei a gostar de rock e ele me emprestava as vezes, eu ia direto na faixa 9 que é sweet child O’mine . Virei um guns maniáco, curtia demais e vieram outras bandas. Em aniversários, Natal, eu pedia para todos da família um cd.  Nirvana, Metallica, ACDC, Red Hot Chili Peppers”, conta. Gustavo tem a discografia completa da banda e revela que enquanto seus amigos colecionavam figurinhas, seu sonho era de completar a coleção do Guns e assim o fez. “O primeiro eu comprei do meu irmão, troquei com ele em quatro cd’s de rock nacional. Eu devia ter uns 10 anos de idade. Depois comprei mais dois dos meus amigos e ganhei da minha falecida avó que era uma grande artista, tocava piano, violão e ganhei um cd duplo Live Era que está na discografia do Guns ao vivo, depois comprei The spaghetti incident e completei minha coleção”, relata. Lopes tem dois discos de vinil da banda e fala sobre o que isso representa em sua vida. “A questão do vinil, é que a geração passada gostava de uma música de qualidade e o vinil tem uma essência que por exemplo, quando coloca o vinil não é uma coisa simples de trocar de música, como hoje na internet, a pessoa escuta e já troca, o vinil era como um livro, quem fazia um álbum queria transmitir uma mensagem para a pessoa, da primeira até a última, era uma sequência, então quem teve a oportunidade de curtir o vinil, curtir o cd foi uma geração muito feliz, porque como disse, era um livro, transmitia uma mensagem”, explica. Ainda segundo o geógrafo, a música sweet child’ o mine também o fez ter vontade de tocar, de ter seus instrumentos, como violão, guitarra e o seu sonho era fazer o solo da música criado por Slash, que aliás, para ele é o grande influenciador dos roqueiros. Quem já teve a oportunidade ir a dois shows do Guns N’ Roses foi Felippe dCosta, músico e publicitário. Felippe conta que estas duas experiências foram no estádio do Palmeiras, que é seu time do coração, uma em 2008 no Parque Antártica com uma formação alternativa. ” Era maior que a original. Para substituir Slash e Gilby Clarke colocaram 3 guitarristas. Era o Guns, era o Axl cantando, mas parecia uma “banda show”. E a segunda em 2016 já no atual Allianz Parque, com a nova formação e ver Slash, Axl e Duff no palco foi algo que me fez lembrar aquele tempo de noites em claro vendo o clipe dos caras. Emocionante e nostálgico. Um turbilhão de sensações”, conta. Guns N’ Roses entrou na vida de Felippe quando seu era pai era dono de uma galeria na cidade Botelhos, nos anos 90 e existia uma locadora de CD. “Quando mudamos para Pouso Alegre, em 1996, ele ficou com alguns cd’s e dentre eles, tinha um cd ao vivo do Guns n’ Roses nomeado como Live in Concert, uma gravação não muito boa em comparação com outro álbum ao vivo como o Live Era. Esse inclusive, foi o primeiro cd que eu juntei dinheiro para comprar. A essa altura já estava deixando o cabelo crescer e querendo uma guitarra. Meus amigos de Botelhos (cidade natal) e Pouso Alegre (onde morava naquela época) também gostavam bastante então foi natural. Estávamos no ‘Boom’ da internet discada, então eram noites em claro baixando músicas, clipes e ouvindo Guns”, relembra. Ainda segundo Felippe, a canção Sweet Child O’ Mine é um hino do rock. “Há controvérsias, mas o prêmio está lá, por uma revista britânica. Para mim, foi uma grande influência junto com Money for Nothing do Dire Straits, para escolher a guitarra como instrumento na época. Se hoje toco em uma banda (Crazed Country Rebels), com certeza tem essa sementinha lá trás, que iniciou o desenvolvimento da minha linguagem musical”, finaliza. </conteudo>\n",
      "</noticia_1>\n",
      "\n",
      "<noticia_2>\n",
      "\t<data>2021-01-29</data>\n",
      "\t<titulo>‘Turma da Mônica – Lições’, gravado em Poços, tem novo teaser com Isabelle Drummond</titulo>\n",
      "\t<autor>ondapocos</autor>\n",
      "\t<link>https://ondapocos.com.br/turma-da-monica-licoes-gravado-em-pocos-tem-novo-teaser-com-isabelle-drummond/</link>\n",
      "\t<conteudo>“Turma da Mônica – Lições”, gravado em Poços de Caldas, segundo filme com atores baseado nos quadrinhos de Mauricio de Sousa, ganhou teaser nesta sexta (29). Assista abaixo. No vídeo, Isabelle Drumond aparece como Tina e Gustavo Merighi como Rolo, dois personagens conhecidos dos quadrinhos. Malu Mader interpreta a professora que explica o que é metamorfose no teaser, e Mônica Iozzi é Dona Luísa, mãe de Mônica. Com direção de Daniel Rezende, o filme está previsto para 2021, mas a data de lançamento não foi divulgada. Na sequência, Mônica (Giulia Benite), Cebolinha (Kevin Vechiatto), Magali (Laura Rauseo) e Cascão (Gabriel Moreira) decidem fugir da escola depois de se esquecerem de fazer o dever de casa, mas algo sai errado. O novo filme, baseado na graphic novel de mesmo nome, mostra os quatro amigos do Bairro do Limoeiro descobrindo os desafios da passagem da infância para a adolescência. “Turma da Mônica – Laços”, primeiro filme com atores baseado nas histórias de Mauricio de Sousa, foi lançado em 2019 e levou mais de 2 milhões de pessoas aos cinemas. Sinopse:?  Mônica, Cebolinha, Magali e Cascão fogem da escola. Agora, terão que encarar as suas consequências, e elas não serão poucas. Nesta nova jornada, a turma descobrirá o real valor e sentido da palavra amizade. Elenco:?  Giulia?Benite?(Mônica), Kevin?Vechiatto?(Cebolinha), Laura?Rauseo?(Magali), Gabriel Moreira (Cascão), Monica?Iozzi?(Dona Luísa), Paulo Vilhena (Seu Cebola), Fafá Rennó (Dona Cebola), Luiz Pacini (Seu Sousa). Participações especiais:   Malu Mader Isabelle Drumond Gustavo Merighi  </conteudo>\n",
      "</noticia_2>\n",
      "\n",
      "<noticia_3>\n",
      "\t<data>2021-09-05</data>\n",
      "\t<titulo>Composição Ferroviária tem apresentação de Mônica Salmaso</titulo>\n",
      "\t<autor>Aline Rodrigues</autor>\n",
      "\t<link>https://ondapocos.com.br/composicao-ferroviaria-tem-apresentacao-de-monica-salmaso/</link>\n",
      "\t<conteudo>O projeto Composição Ferroviária segue em seus trilhos digitais aguardando segurança sanitária para voltar as suas atividades presenciais. Este ano, já passaram pelo canal do YouTube do projeto quatro shows com grandes nomes e grande repercussão. Neste domingo,05, a primavera desponta no palco do Composição junto com o show de Mônica Salmaso, com abertura de Wolf Borges e Zé Helder. Mônica Salmaso iniciou sua carreira na peça “O Concílio do Amor”, em 1989. Em 1995, gravou o disco “Afro-Sambas”, um duo de voz e violão com Paulo Bellinati, incluindo todos os afro-sambas de Baden Powell e Vinícius de Moraes. Em 1997, foi indicada ao Prêmio Sharp como revelação na categoria MPB. Lançou “Trampolim”, em 1998, e “Voadeira”, um ano depois, com o qual ganhou o prêmio APCA. O quarto CD, “IAIÁ”, nasceu em 2004, seguido por “Noites de Gala, Samba na Rua”, de 2007, com músicas de Chico Buarque. Com o CD “Alma Lírica Brasileira”, com Teco Cardoso e Nelson Ayres, lançado pela Biscoito Fino em 2011, recebeu o 23º Prêmio da Música Brasileira, na categoria Melhor Cantora. Seu penúltimo CD, “Corpo de Baile” (2014), com músicas de Guinga e Paulo César Pinheiro, recebeu quatro indicações ao Prêmio da Música Brasileira, das quais venceu duas – melhor cantora MPB e melhor canção. Em 2017, lançou o álbum “Caipira” que recebeu elogios da crítica especializada e ganhou os prêmios de Melhor Álbum e Melhor Cantora – Categoria Regional no 29º Prêmio da Música Brasileira. Tem sido convidada regularmente para ministrar aulas em festivais no Brasil e exterior. A gravadora Biscoito Fino acaba de lançar no Brasil o CD gravado na turnê pelo Japão com Guinga em 2019 e dentre as atividades de 2021 terá a continuação da turnê nacional do CD Caipira. Em março de 2020, Mônica iniciou os vídeos Ô de Casas, não como um projeto, mas sim como uma forma de promover encontros virtuais com os amigos no inicio da pandemia, batizados por ela como “Encontros quentinhos de des-isolamento responsável”, que seguem até hoje. Para o Composição Ferroviária Mônica produziu especialmente um show com canções de Edu Lobo, com a participação dos músicos Paulo Aragão e Teco Cardoso. A abertura do show de Mônica Salmaso será feita pelo cantor e compositor (e também produtor do projeto) Wolf Borges, acompanhado pelo violeiro Zé Helder. Wolf Borges é uma referência na produção artística e cultural da região, lançando este ano o 8º CD comemorando seus 40 anos de carreira musical. Zé Helder integra as bandas Matuto Moderno e Moda de Rock, tendo excursionado com estes trabalhos por todo o Brasil, Estados Unidos, Argentina, México e Canadá. O projeto Composição Ferroviária é viabilizado pela Lei Estadual de Incentivo à Cultura de Minas Gerais e tem o patrocínio do DME, Intercast e Doces São Lourenço.   Serviço: Show de Mônica Salmaso com abertura de Wolf Borges e Zé Helder Dia 5 de setembro, domingo, às 10h da manhã No YouTube: https://bityli.com/UmicF (Canal Mecenaria Brasil). </conteudo>\n",
      "</noticia_3>```\n",
      "\n",
      "## CHAT HISTORY\n",
      "```Human: Qual foi a notícia de acidente de moto mais antiga?\n",
      "AI: {\n",
      "    \"resposta\": \"A notícia mais antiga de acidente de moto é sobre o acidente registrado na cidade de Poços de Caldas, onde um homem quase atropelou pedestres ao praticar manobras perigosas.\",\n",
      "    \"link\": \"https://ondapocos.com.br/policia-civil-apreende-moto-usada-por-homem-que-quase-atropelou-pedestres-em-pocos/\",\n",
      "    \"data\": \"2023-04-18\",\n",
      "    \"titulo\": \"Polícia Civil apreende moto usada por homem que quase atropelou pedestres em Poços\",\n",
      "    \"autor\": \"Matheus Luis\"\n",
      "}\n",
      "```\n",
      "\n",
      "## HUMAN INPUT\n",
      "`E a mais recente?`\n",
      "\n",
      "IA:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n    \"resposta\": \"A notícia mais recente é sobre a apresentação de Mônica Salmaso no projeto Composição Ferroviária em Poços de Caldas.\",\\n    \"link\": \"https://ondapocos.com.br/composicao-ferroviaria-tem-apresentacao-de-monica-salmaso/\",\\n    \"data\": \"2021-09-05\",\\n    \"titulo\": \"Composição Ferroviária tem apresentação de Mônica Salmaso\",\\n    \"autor\": \"Aline Rodrigues\"\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"E a mais recente?\"\n",
    "\n",
    "query_handler = QueryHandler(llm_model=config.LLM_MODEL_NAME, memory=memory, vector_database=vdb, verbose=True)\n",
    "\n",
    "context = query_handler.get_context(query)\n",
    "\n",
    "query_handler.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbc57b-6986-47c9-80ed-525368bc7e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b3fff-efd3-4cfd-b8c0-c40e3ebaff16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d72b7e-142e-43c1-bcb8-8194e4031d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5273cf57-6605-4589-941f-57eb024fa808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "# import tiktoken\n",
    "# from langchain.memory.chat_memory import BaseChatMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from bot.handlers import PublicHandler\n",
    "# from bot.vector_databases.base import VectorDB\n",
    "# from bot.data_models import News, VectorDatabaseNewsResult\n",
    "\n",
    "# class QueryHandler(PublicHandler):\n",
    "#     _prompt_key: str = \"prompt_query\"\n",
    "#     _use_chat_history: bool = True\n",
    "#     _use_context: bool = True\n",
    "    \n",
    "#     def __init__(self, llm_model: str, memory: BaseChatMemory, vector_database: VectorDB, temperature: float = 0, verbose: bool = True, \n",
    "#                 llm_context_window_size: int = 4096, prompt_max_tokens: int = 3200):\n",
    "        \n",
    "#         self._llm_model = llm_model\n",
    "#         self._memory = memory\n",
    "#         self._temperature = temperature\n",
    "#         self._verbose = verbose\n",
    "#         self._vector_database = vector_database\n",
    "#         self._llm_context_window_size = llm_context_window_size\n",
    "#         self._prompt_max_tokens = prompt_max_tokens\n",
    "\n",
    "#     @property\n",
    "#     def temperature(self):\n",
    "#         return self._temperature\n",
    "        \n",
    "#     @property\n",
    "#     def verbose(self):\n",
    "#         return self._verbose\n",
    "        \n",
    "#     @property\n",
    "#     def llm_model(self):\n",
    "#         return self._llm_model\n",
    "        \n",
    "#     @property\n",
    "#     def memory(self):\n",
    "#         return self._memory\n",
    "        \n",
    "#     @property\n",
    "#     def vector_database(self):\n",
    "#         return self._vector_database\n",
    "        \n",
    "#     @property\n",
    "#     def prompt_key(self):\n",
    "#         return self._prompt_key\n",
    "        \n",
    "#     @property\n",
    "#     def use_chat_history(self):\n",
    "#         return self._use_chat_history\n",
    "\n",
    "#     @property\n",
    "#     def use_context(self):\n",
    "#         return self._use_context\n",
    "\n",
    "#     @property\n",
    "#     def llm_context_window_size(self):\n",
    "#         return self._llm_context_window_size\n",
    "\n",
    "#     @property\n",
    "#     def prompt_max_tokens(self):\n",
    "#         return self._prompt_max_tokens\n",
    "\n",
    "#     @property\n",
    "#     def llm(self):\n",
    "#         return ChatOpenAI(\n",
    "#             model_name=self.llm_model,\n",
    "#             temperature=self.temperature\n",
    "#         )\n",
    "\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620218a0-21a8-4ce2-ab15-9821caf0ac67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74027883-0f53-46ab-b893-fe9c25b4aad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Olá. Tudo bem?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0f12ce-bd60-4807-a330-943561942f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<data>2020-04-16</data>\n",
      "<titulo>QUARENTENA| Saiba como manter a segurança das crianças e evitar acidentes domésticos</titulo>\n",
      "<autor>ondapocos</autor>\n",
      "<link>https://ondapocos.com.br/quarentena-saiba-como-manter-a-seguranca-das-criancas-e-evitar-acidentes-domesticos/</link>\n",
      "<conteudo>Neste período de quarentena, toda prevenção é sempre válida. Principalmente para quem tem crianças em casa. O jornalismo da Onda Poços falou com os Bombeiros sobre como prevenir e evitar acidentes domésticos. Segundo os militares existem muitos objetos que representam potenciais riscos de acidentes para as crianças. A principal causa de hospitalização de crianças entre 0 a 14 anos no Brasil é por acidentes domésticos, sendo mais de 100.000 internações por ano e cerca de 3.000 são fatais. A jornalista Maria Paula Paiva tem uma criança de onze meses e reforça os cuidados com os brinquedos pequenos. “No caso de peças de lego é sempre bom lavar elas com água sanitária pelo menos a cada 15 dias com toda essa situação, porque as crianças levam elas à boca o tempo todo”. Confira abaixo algumas dicas de segurança dos Bombeiros:    </conteudo>\n",
      "\n",
      "<data>2021-08-20</data>\n",
      "<titulo>ONDA MAIS | Neurologista fala sobre sono, perda de memória e ansiedade</titulo>\n",
      "<autor>Aline Rodrigues</autor>\n",
      "<link>https://ondapocos.com.br/onda-mais-neurologista-fala-sobre-sono-perda-de-memoria-e-ansiedade/</link>\n",
      "<conteudo>O neurologista Eduardo Leite Ribeiro do Valle foi o convidado do Onda Mais desta terça-feira,17. Em bate-papo descontraído o médico abordou assuntos como a ansiedade, alzheimer, a importância de dormir bem, e os impactos da covid-19. Vem conferir essa conversa:    </conteudo>\n",
      "\n",
      "<data>2022-01-20</data>\n",
      "<titulo>Entrevista de garoto autista de Poços ganha repercussão e é compartilhada por famosos no Brasil</titulo>\n",
      "<autor>Matheus Luis</autor>\n",
      "<link>https://ondapocos.com.br/entrevista-de-garoto-autista-de-pocos-ganha-repercussao-e-e-compartilhada-por-famosos-no-brasil/</link>\n",
      "<conteudo>O trecho de uma reportagem realizada pelos jornalistas Matheus Luis, Alice Dionisio e o cinegrafista Aroldo Esmeraldino, da emissora local de Poços de Caldas, TV Poços, viralizou na internet. A cobertura era sobre o início da vacinação infantil contra Covid-19 no município. Um dos entrevistados da reportagem, Nicolas Takata Muniz, de 11 anos, que é autista, viralizou após ele conquistar a todos com sua fala na entrevista ganhando o coração de muitos famosos do Brasil. “Estou muito feliz, dá até para comer um pastelzinho com guaraná iria ser top, um beijo para todas as Letícias e Pedrinhos do Brasil. Não acredita nas palavras do Bolsonaro não, podem mandar seus filhos tomarem agulhada, está super tranquilo, o máximo que pode ter é uma criança chorona e um braço dolorido nada além disso, você não vai virar nem um jacaré e nem uma formiga australiana”, disse o garoto. Nicolas está recebendo carinho de muitas pessoas. Até pastel ele recebeu em casa enviado por um fã. Entre os famosos que compartilharam o vídeo, está o colunista Hugo Gloss, que tem mais de 19 milhões de seguidores em suas redes sociais. O post já tem mais de 1 milhão de acessos e contou com comentários de vários famosos entre eles o do apresentador da rede Globo Marcos Mion e também do apresentador Iude. Marina Silva, que foi candidata à Presidência nas últimas três campanhas e a Mídia Ninja, rede de mídia com atuação em mais de 250 cidades no Brasil, também compartilharam o post. </conteudo>\n",
      "\n",
      "<data>2022-07-04</data>\n",
      "<titulo>Férias: como evitar acidentes com as crianças no período de lazer</titulo>\n",
      "<autor>Matheus Luis</autor>\n",
      "<link>https://ondapocos.com.br/ferias-como-evitar-acidentes-com-as-criancas-no-periodo-de-lazer/</link>\n",
      "<conteudo>Julho chegou e o período de férias escolares para as crianças e os adolescentes também. Aguardada pelos pequenos (e não tão pequenos) pelas numerosas possibilidades de lazer, brincadeiras e descanso, as férias alteram as rotinas o que aumenta os riscos de pequenos acidentes, quedas e traumas dentro e fora de casa. No ambiente doméstico, os responsáveis precisam cuidar de situações como queimaduras, envenenamento, afogamento, quedas, cortes, sufocação e choque elétrico. Tanto dentro quanto fora de casa é preciso estar atento ao movimento das crianças. Os acidentes mais comuns nas emergências são pequenos ferimentos e contusões, segundo o ortopedista pediátrico, Wilson Lino Junior. “As crianças estão sempre em movimento e procurando aventuras e interação com seus semelhantes. Devemos pensar em alguns fatores que podem justificar a maior quantidade de traumas e acidentes: a coordenação das crianças está em constante desenvolvimento, a marcha normal só se assemelha a de um adulto aos 6 anos de idade, mudanças corporais ocorrem até a fase final de crescimento, próximo dos 16 anos de idade”. Segundo o médico, a criança cresce muito ao longo de pouco tempo e a relação com o mundo que a envolve muda constantemente. “Imagine que uma mesa tem a altura padrão de 80cm, uma criança aos 2 anos de idade pode passar por baixo da mesa sem necessitar abaixar e, em menos de um ano, precisa recalibrar seus parâmetros, pois se não abaixar irá bater a cabeça, um dos traumas mais comuns vistos nas emergências.” Após o acidente, a orientação é observar a criança. “Desmaios e vômitos são sinais de alerta com traumas de cabeça. Deformidades, dor intensa nos membros são sinais de fratura. Ferimentos cortantes com sangramento abundante também devem levar ao pronto-socorro”, enumera o médico. “No caso de trauma nos membros, recomenda-se imobilização provisória, nos ferimentos sangrantes deve-se envolver com toalha ou pano limpo e não fazer garrotes e torniquetes. Nunca colocar substâncias como café, óleo, pasta de dente e outros produtos de crendices que podem contaminar os ferimentos, causar infecções graves e dificultar o tratamento”, alerta o ortopedista. Segundo Lino Junior, os acidentes mais frequentes costumam ocorrer dentro de casa, onde os pais, em geral, estão mais tranquilos por considerar um ambiente seguro. Engasgos Além dos acidentes, há ainda outras situações inesperadas, entre elas, o engasgo, que costuma ocorrer com as crianças menores de 5 anos, de acordo com a otorrinolaringologista Saramira Bohadana. “A criança na fase oral, normalmente, põe tudo na boca. Se o objeto for pequeno, a criança tem risco de aspirar ou de deglutir. Os objetos que representam mais risco para a criança são as baterias. Então os pais devem tomar muito cuidado para que não tenha em casa brinquedos com baterias pequenas, porque as baterias que não são alcalinas, em contato com a mucosa tanto nasal quanto a mucosa digestiva,  corroem a mucosa e provocam perfuração e destruição do tecido e isso é extremamente grave, a criança deve ser atendida o mais rápido possível”, alerta a médica. Ela reforça que não se deve esperar para ver se o objeto sai nas fezes. “A família da criança deve sempre procurar o pronto-socorro mais próximo quando perceber que a criança se engasgou ou se ela teve algum acidente com o corpo estranho e nunca esperar para ver o que vai acontecer ou se vai eliminar nas fezes”. Difícil encontrar uma criança que não goste de pipoca, mas as menores devem ficar longe do alimento, assim como do amendoim, pelo alto risco de engasgo, acrescentou a médica Objetos perigosos Segundo a médica, os principais acidentes com engasgos ocorrem com pedras de roupa, bijuterias, borracha, plástico, pedaço de brinquedo e comida, especialmente pipoca. As crianças podem engasgar tanto deglutindo quanto aspirando esses objetos para via aérea. “Os casos de aspiração de objetos para via aérea são mais raros, mas o de deglutição são os mais frequentes. Na nossa estatística 36% dos casos foram de via digestiva. Enquanto que 31% foram objetos colocados na cavidade oral e 5% dos casos foram de orofarine e 27% dos casos são objetos colocados no ouvido”, detalha a especialista. Prevenção Para diminuir a chance de acidentes dentro de casa, alguns cuidados são importantes: – Colocar protetores que evitem o fechamento repentino de portas – situação que pode causar acidentes graves, como amputação de pontas de dedos das crianças. – Televisões e objetos mais pesados devem ser fixos, para evitar a queda. – Deixar os brinquedos ao alcance da criança. Remédios e produtos de limpeza devem ficar sempre longe do alcance dos pequenos. – Explicar e mostrar os riscos de um fogão ou forno enquanto estiver cozinhando. Emergência O número 193, do Corpo de Bombeiros, recebe chamados para acidentes domésticos com crianças todos os dias. No período das férias escolares, entretanto, esse índice aumenta. Para evitar os acidentes, abaixo estão algumas orientações: – Piscinas: as crianças devem estar sempre na companhia de um adulto e utilizar equipamentos de segurança, como boias. – Panelas e fogão: os cabos das panelas devem estar voltados para dentro do fogão, para evitar que a criança puxe o cabo e se queime ou derrame água quente. Permanecer com o fogão desligado sempre que possível. – Energia elétrica: Evitar o uso de eletrônicos, como celular, enquanto o aparelho carrega, para evitar descargas elétricas e explosões. via Agência Brasil </conteudo>\n",
      "\n",
      "<data>2022-10-06</data>\n",
      "<titulo>Chuvas causam preocupações e alertas na região</titulo>\n",
      "<autor>Camila Almeida</autor>\n",
      "<link>https://ondapocos.com.br/chuvas-causam-preocupacoes-e-alertas-na-regiao/</link>\n",
      "<conteudo>As chuvas intensas causaram preocupações na população, pois os riscos no período chuvoso intensificam. Segundo dados do Instituto de Pesquisas Espaciais (Inpe), o Brasil é o país com a  maior incidência de raios no mundo. Para diminuir os riscos de acidente é preciso estar atento a pequenos cuidados para evitar acidentes que podem levar à morte. Procurar locais seguros, como um estabelecimento comercial, e não ficar debaixo de árvores ou postes, que podem atrair a descarga atmosférica e eletrocutar quem esteja próximo, estão entre as dicas de prevenção da Cemig. </conteudo>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69199cc-e544-44f9-9d1e-ffe9c5f936bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa16cc1-b03c-4f51-bfc1-0baf5b28a759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d400c147-2f97-4707-a87d-5ed51ff70e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "LLM_CONTEXT_WINDOW_SIZE = 4096\n",
    "PROMPT_MAX_TOKENS = 3200\n",
    "\n",
    "\n",
    "def get_content(self, query, n_results=10, n_neighbors=1000):\n",
    "    results = query_handler.vector_database.get_most_similar(\"assédio\")\n",
    "\n",
    "    return self._set_query_content(result[\"documents\"][0], result[\"metadatas\"][0])\n",
    "\n",
    "\n",
    "def _set_query_content(results):\n",
    "    \n",
    "    context_list = [format_news(res.news) for res in results]\n",
    "\n",
    "    tokens = LLM_CONTEXT_WINDOW_SIZE\n",
    "    max_tokens = PROMPT_MAX_TOKENS\n",
    "    while tokens > max_tokens:\n",
    "        tokens = self.count_tokens(\"\\n\".join(context_list))\n",
    "        if tokens >= max_tokens:\n",
    "            context_list.pop()\n",
    "\n",
    "    return \"\\n\".join(sorted(context_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58d019e1-7bc4-4e9a-9256-f02a694ace4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m docs \u001b[38;5;241m=\u001b[39m query_handler\u001b[38;5;241m.\u001b[39mvector_database\u001b[38;5;241m.\u001b[39mget_most_similar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massédio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43m_set_query_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 31\u001b[0m, in \u001b[0;36m_set_query_content\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     29\u001b[0m max_tokens \u001b[38;5;241m=\u001b[39m PROMPT_MAX_TOKENS\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m tokens \u001b[38;5;241m>\u001b[39m max_tokens:\n\u001b[0;32m---> 31\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mcount_tokens(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(context_list))\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokens \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_tokens:\n\u001b[1;32m     33\u001b[0m         context_list\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "docs = query_handler.vector_database.get_most_similar(\"assédio\")\n",
    "\n",
    "_set_query_content(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a3da851-09dc-47f5-a614-450f622eaa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<data>2022-06-18</data>\n",
      "<titulo>Polícia Civil de Poços abre inquérito para investigar segundo caso de injúria racial em menos de um mês</titulo>\n",
      "<autor>Matheus Luis</autor>\n",
      "<link>https://ondapocos.com.br/policia-civil-de-pocos-abre-inquerito-para-investigar-segundo-caso-de-injuria-racial-em-menos-de-um-mes/</link>\n",
      "<conteudo>A Polícia Civil de Poços de Caldas investiga mais um caso de injúria racial em menos de um mês. Desta vez os ataques foram feitos por uma rede social. A discussão em um grupo no início do mês era sobre perfis falsos na internet. Jéssica Nuevo da Silva participava das discussões, mas um comentário a deixou indignada. Uma mulher escreveu: “Quem sabe um creminho bom no cabelo que te odeia”. Segundo o Boletim de Ocorrência, a suspeita começou os ataques chamando a vítima de burra, feia, até que ela pegou uma foto dela na rede social, printou essa foto e fez um comentário bem racista sobre o cabelo. A ofensa ficou tempo suficiente no grupo da rede social para que a vítima pudesse printar a conversa e logo em seguinte registrar uma denúncia por injúria racial. A Jéssica, que é integrante do Movimento Negro de Poços de Caldas, aguarda as investigações. A Polícia Civil já abriu inquérito para apurar o caso. Este foi o segundo caso registrado em menos de um mês. Dias antes, uma prestadora de serviços também foi vítima de suposta injúria racial em uma agência do Banco do Brasil. Priscila Cristina Martins afirma que uma mulher que trabalhava com ela no setor de limpeza teria dito que o chão estaria sujo, assim como a cor da pele dela. Com informações do G1 </conteudo>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = docs[0]\n",
    "news = res.news\n",
    "\n",
    "print(_set_local_context(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b805045d-9d37-4385-8616-794b020be9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "News(id=UUID('661ba0de-05df-5ea6-be74-2306d7dbe209'), title='Polícia Civil de Poços abre inquérito para investigar segundo caso de injúria racial em menos de um mês', document='A Polícia Civil de\\xa0Poços de Caldas\\xa0investiga mais um caso de injúria racial em menos de um mês. Desta vez os ataques foram feitos por uma rede social. A discussão em um grupo no início do mês era sobre perfis falsos na internet. Jéssica Nuevo da Silva participava das discussões, mas um comentário a deixou indignada. Uma mulher escreveu: “Quem sabe um creminho bom no cabelo que te odeia”. Segundo o Boletim de Ocorrência, a suspeita começou os ataques chamando a vítima de burra, feia, até que ela pegou uma foto dela na rede social, printou essa foto e fez um comentário bem racista sobre o cabelo. A ofensa ficou tempo suficiente no grupo da rede social para que a vítima pudesse printar a conversa e logo em seguinte registrar uma denúncia por injúria racial. A Jéssica, que é integrante do Movimento Negro de\\xa0Poços de Caldas, aguarda as investigações. A Polícia Civil já abriu inquérito para apurar o caso. Este foi o segundo caso registrado em menos de um mês. Dias antes, uma prestadora de serviços também foi vítima de suposta injúria racial em uma agência do Banco do Brasil. Priscila Cristina Martins afirma que uma mulher que trabalhava com ela no setor de limpeza teria dito que o chão estaria sujo, assim como a cor da pele dela. Com informações do G1 ', date=datetime.date(2022, 6, 18), link='https://ondapocos.com.br/policia-civil-de-pocos-abre-inquerito-para-investigar-segundo-caso-de-injuria-racial-em-menos-de-um-mes/', author='Matheus Luis', categories=['Destaques', 'Notícias', 'Policial'], snippet='A Polícia Civil de\\xa0Poços de Caldas\\xa0investiga mais um caso de injúria racial em menos de um mês. Desta vez os ataques foram feitos por uma...', thumbnail_alt='Homem é preso por fazer sexo com cachorra em Campestre-MG', thumbnail_link='https://i1.wp.com/ondapocos.com.br/wp-content/uploads/2022/03/POLÍCIA-CIVIL.jpg?resize=350%2C250&ssl=1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ee4a5-b7df-4079-be7f-cbfef020e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar = vdb.get_most_similar(improved_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4200e77-2fa6-4eaa-9c06-50fb7fec6b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/configuration_utils.py:387: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "    # from bot import NewsBot\n",
    "    \n",
    "    # news_bot = NewsBot(local_filepath=\"./teste.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c36228-cf67-4db0-a007-5e37e6f2a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from importlib import resources\n",
    "from typing import List\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.base import Chain\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from bot import BotConfig\n",
    "\n",
    "config = BotConfig()\n",
    "\n",
    "\n",
    "class Handler(ABC):\n",
    "    prompts_folder: str = \"bot.prompts\"\n",
    "    human_prefix: str = config.HUMAN_PREFIX\n",
    "    ai_prefix: str = config.AI_PREFIX\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_prompt(self, key: str) -> PromptTemplate:\n",
    "        filepath = str(resources.files(self.prompts_folder).joinpath(f\"{key}.json\"))\n",
    "        return load_prompt(filepath)\n",
    "\n",
    "    def predict(self, message) -> str:\n",
    "        params = {}\n",
    "        if self.use_chat_history:\n",
    "            params.update(dict(history=self.get_chat_history()))\n",
    "        return self.chain.predict(human_input=message, **params)\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def llm(self) -> BaseChatModel:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def prompt_key(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def temperature(self) -> float:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def verbose(self) -> bool:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def llm_model(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def memory(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def prompt(self) -> PromptTemplate:\n",
    "        return self.get_prompt(self.prompt_key)\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def chain(self) -> Chain:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def use_chat_history(self) -> Chain:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def get_chat_history(self) -> str:\n",
    "        _class = self.__class__\n",
    "        if hasattr(_class, \"memory\"):\n",
    "            return \"\".join(\n",
    "                self.format_history_message(self.memory.chat_memory.messages)\n",
    "            )\n",
    "        raise AttributeError(f\"The class {_class.__name__} does not have the 'memory' attribute\")\n",
    "\n",
    "    def format_history_message(self, messages: List[HumanMessage | AIMessage]):\n",
    "        for message in messages:\n",
    "            if isinstance(message, HumanMessage):\n",
    "                yield f\"{config.HUMAN_PREFIX}: {message.content}\\n\"\n",
    "    \n",
    "            elif isinstance(message, AIMessage):\n",
    "                yield f\"{config.AI_PREFIX}: {message.content}\\n\"\n",
    "\n",
    "class PrivateHandler(Handler, ABC):\n",
    "    @property\n",
    "    def chain(self) -> Chain:\n",
    "        return LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "\n",
    "class PublicHandler(Handler, ABC):\n",
    "    @property\n",
    "    def chain(self) -> Chain:\n",
    "        return LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=self.verbose,\n",
    "            memory=self.memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4a68a9-a5f9-46d6-8a00-d9d29ba4be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "from bot.handlers import PrivateHandler\n",
    "\n",
    "\n",
    "class StandaloneHandler(PrivateHandler):\n",
    "    _prompt_key: str = \"prompt_standalone_question\"\n",
    "    _use_chat_history: bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_model: str,\n",
    "        memory: BaseChatMemory,\n",
    "        temperature: float = 0,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        self._llm_model = llm_model\n",
    "        self._memory = memory\n",
    "        self._temperature = temperature\n",
    "        self._verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "\n",
    "    @property\n",
    "    def verbose(self):\n",
    "        return self._verbose\n",
    "\n",
    "    @property\n",
    "    def llm_model(self):\n",
    "        return self._llm_model\n",
    "\n",
    "    @property\n",
    "    def memory(self):\n",
    "        return self._memory\n",
    "\n",
    "    @property\n",
    "    def prompt_key(self):\n",
    "        return self._prompt_key\n",
    "\n",
    "    @property\n",
    "    def use_chat_history(self):\n",
    "        return self._use_chat_history\n",
    "\n",
    "    @property\n",
    "    def llm(self):\n",
    "        return ChatOpenAI(model_name=self.llm_model, temperature=self.temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeffe33b-08ca-4af8-8de9-88c1c1649c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "from bot.handlers import PrivateHandler\n",
    "\n",
    "\n",
    "class IntentionHandler(PrivateHandler):\n",
    "    _prompt_key: str = \"prompt_user_intention\"\n",
    "    _use_chat_history: bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_model: str,\n",
    "        memory: BaseChatMemory,\n",
    "        temperature: float = 0,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        self._llm_model = llm_model\n",
    "        self._memory = memory\n",
    "        self._temperature = temperature\n",
    "        self._verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "\n",
    "    @property\n",
    "    def verbose(self):\n",
    "        return self._verbose\n",
    "\n",
    "    @property\n",
    "    def llm_model(self):\n",
    "        return self._llm_model\n",
    "\n",
    "    @property\n",
    "    def memory(self):\n",
    "        return self._memory\n",
    "\n",
    "    @property\n",
    "    def prompt_key(self):\n",
    "        return self._prompt_key\n",
    "\n",
    "    @property\n",
    "    def use_chat_history(self):\n",
    "        return self._use_chat_history\n",
    "\n",
    "    @property\n",
    "    def llm(self):\n",
    "        return ChatOpenAI(model_name=self.llm_model, temperature=self.temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30034eed-4abb-4242-b2d5-9aa238c95559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a235fd51-1b0c-433e-8336-5cd3fb0400a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    collection, query, n_neighbors: int = 1000, n_results: int = 10, **kwargs\n",
    "):\n",
    "    def f(key, value, k):\n",
    "        def limit(x):\n",
    "            if isinstance(x, list):\n",
    "                return x[:k]\n",
    "            return x\n",
    "\n",
    "        if isinstance(value, list):\n",
    "            return (key, [limit(x) for x in value])\n",
    "        return (key, None)\n",
    "\n",
    "    res = collection.query(\n",
    "        query_texts=query,\n",
    "        n_results=n_neighbors,\n",
    "        **kwargs\n",
    "        # where={\"metadata_field\": \"is_equal_to_this\"},\n",
    "        # where_document={\"$contains\":\"search_string\"}\n",
    "    )\n",
    "\n",
    "    return dict([f(key, value, n_results) for key, value in res.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a83a6-2bea-45f2-8dc2-7ea1e28f84d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05254e-e800-4da5-a880-d13e74e92744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60be8ee-d972-479a-b032-f01f2b3afa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=clips-mfaq)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get_similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3160ce-cef7-4156-8360-909ee078664a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b31ff-633b-40ec-a566-dee10ae3628e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2da80-942a-4ac6-bb99-e2bbf8c2c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.handlers import PublicHandler\n",
    "\n",
    "class QueryHandler(PublicHandler):\n",
    "    _prompt_key: str = \"prompt_user_intention\"\n",
    "    _use_chat_history: bool = True\n",
    "    \n",
    "    def __init__(self, llm_model: str, memory: BaseChatMemory, temperature: float = 0, verbose: bool = True, ):\n",
    "        self._llm_model = llm_model\n",
    "        self._memory = memory\n",
    "        self._temperature = temperature\n",
    "        self._verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "        \n",
    "    @property\n",
    "    def verbose(self):\n",
    "        return self._verbose\n",
    "        \n",
    "    @property\n",
    "    def llm_model(self):\n",
    "        return self._llm_model\n",
    "        \n",
    "    @property\n",
    "    def memory(self):\n",
    "        return self._memory\n",
    "        \n",
    "    @property\n",
    "    def prompt_key(self):\n",
    "        return self._prompt_key\n",
    "        \n",
    "    @property\n",
    "    def use_chat_history(self):\n",
    "        return self._use_chat_history\n",
    "\n",
    "    @property\n",
    "    def llm(self):\n",
    "        return ChatOpenAI(\n",
    "            model_name=self.llm_model,\n",
    "            temperature=self.temperature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c334c-0a07-4dd1-affe-bc91a98dbf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a1b84-529a-42ab-8759-002d0dbb3a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45672cd1-7ed3-4249-9226-55a3cfdf3228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4956944-53b5-4ea5-9bb1-1837a8f0ed8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572dc27-d485-4ce3-a3ab-3859c3f972b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d86abb-6182-4145-9b05-41d98bb34da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914891f6-5af5-4fdf-8b99-94b7a9a2f60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96edd199-7ce1-4687-89ec-0505dfc0ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "from langchain.chains.base import Chain\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "\n",
    "from bot import BotConfig\n",
    "\n",
    "class Handler(ABC):\n",
    "    prompts_folder: str = \"bot.prompts\"\n",
    "    human_prefix: str = \"Human\"\n",
    "    ai_prefix: str = \"AI\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_prompt(self, key: str) -> PromptTemplate:\n",
    "        filepath = str(resources.files(self.prompts_folder).joinpath(f\"{key}.json\"))\n",
    "        return load_prompt(filepath)\n",
    "\n",
    "    def predict(self, message) -> str:\n",
    "        params = {}\n",
    "        if self.use_chat_history:\n",
    "            params.update(dict(history=self.get_chat_history()))\n",
    "        return self.chain.predict(human_input=message, **params)\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def llm(self) -> BaseChatModel:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def prompt_key(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def temperature(self) -> float:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def verbose(self) -> bool:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def llm_model(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def memory(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def prompt(self) -> PromptTemplate:\n",
    "        return self.get_prompt(self.prompt_key)\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def chain(self) -> Chain:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def use_chat_history(self) -> Chain:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def get_chat_history(self) -> str: # Adicionar typehints nos argumentos ####################################################\n",
    "        _class = self.__class__\n",
    "        if hasattr(_class, \"memory\"):\n",
    "            return \"\".join(\n",
    "                self.format_history_message(self.memory.chat_memory.messages)\n",
    "            )\n",
    "        raise AttributeError(f\"The class {_class.__name__} does not have the 'memory' attribute\")\n",
    "\n",
    "    def format_history_message(self, messages:...): # Adicionar typehints nos argumentos ####################################################\n",
    "        for message in messages:\n",
    "            if isinstance(message, langchain_core.messages.human.HumanMessage):\n",
    "                yield f\"{human_prefix}: {message.content}\\n\"\n",
    "    \n",
    "            elif isinstance(message, langchain_core.messages.ai.AIMessage):\n",
    "                yield f\"{ai_prefix}: {message.content}\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc836d84-46ab-4650-b2e9-ff7756bc3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandlerWithNoMemory(Handler, ABC):\n",
    "    @property\n",
    "    def chain(self) -> Chain:\n",
    "        return LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "\n",
    "class HandlerWithMemory(Handler, ABC):\n",
    "    @property\n",
    "    def chain(self) -> Chain:\n",
    "        return LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=self.verbose,\n",
    "            memory=self.memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3df59456-b61d-4e81-ba10-e1ee4391c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandaloneHandler(HandlerWithNoMemory):\n",
    "    _prompt_key: str = \"prompt_standalone_question\"\n",
    "    _use_chat_history: bool = True\n",
    "    \n",
    "    def __init__(self, llm_model: str, memory: BaseChatMemory, temperature: float = 0, verbose: bool = True, ):\n",
    "        self._llm_model = llm_model\n",
    "        self._memory = memory\n",
    "        self._temperature = temperature\n",
    "        self._verbose = verbose\n",
    "\n",
    "    def predict(self, message: str, ):\n",
    "        return self.chain.predict(\n",
    "            human_input=message,\n",
    "            history=self.get_chat_history(),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "        \n",
    "    @property\n",
    "    def verbose(self):\n",
    "        return self._verbose\n",
    "        \n",
    "    @property\n",
    "    def llm_model(self):\n",
    "        return self._llm_model\n",
    "        \n",
    "    @property\n",
    "    def memory(self):\n",
    "        return self._memory\n",
    "        \n",
    "    @property\n",
    "    def prompt_key(self):\n",
    "        return self._prompt_key\n",
    "        \n",
    "    @property\n",
    "    def use_chat_history(self):\n",
    "        return self._use_chat_history\n",
    "\n",
    "    @property\n",
    "    def llm(self):\n",
    "        return ChatOpenAI(\n",
    "            model_name=self.llm_model,\n",
    "            temperature=self.temperature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a7c8ff6-f4ce-4b24-b6f0-6d96038b2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentionHandler(HandlerWithNoMemory):\n",
    "    _prompt_key: str = \"prompt_user_intention\"\n",
    "    _use_chat_history: bool = True\n",
    "    \n",
    "    def __init__(self, llm_model: str, memory: BaseChatMemory, temperature: float = 0, verbose: bool = True, ):\n",
    "        self._llm_model = llm_model\n",
    "        self._memory = memory\n",
    "        self._temperature = temperature\n",
    "        self._verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "        \n",
    "    @property\n",
    "    def verbose(self):\n",
    "        return self._verbose\n",
    "        \n",
    "    @property\n",
    "    def llm_model(self):\n",
    "        return self._llm_model\n",
    "        \n",
    "    @property\n",
    "    def memory(self):\n",
    "        return self._memory\n",
    "        \n",
    "    @property\n",
    "    def prompt_key(self):\n",
    "        return self._prompt_key\n",
    "        \n",
    "    @property\n",
    "    def use_chat_history(self):\n",
    "        return self._use_chat_history\n",
    "\n",
    "    @property\n",
    "    def llm(self):\n",
    "        return ChatOpenAI(\n",
    "            model_name=self.llm_model,\n",
    "            temperature=self.temperature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fcaea9-aaea-4ccb-8db1-083b0f0a9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryHandler(HandlerWithNoMemory):\n",
    "    _prompt_key: str = \"prompt_user_intention\"\n",
    "    _use_chat_history: bool = True\n",
    "    \n",
    "    def __init__(self, llm_model: str, memory: BaseChatMemory, temperature: float = 0, verbose: bool = True, ):\n",
    "        self._llm_model = llm_model\n",
    "        self._memory = memory\n",
    "        self._temperature = temperature\n",
    "        self._verbose = verbose\n",
    "\n",
    "    @property\n",
    "    def temperature(self):\n",
    "        return self._temperature\n",
    "        \n",
    "    @property\n",
    "    def verbose(self):\n",
    "        return self._verbose\n",
    "        \n",
    "    @property\n",
    "    def llm_model(self):\n",
    "        return self._llm_model\n",
    "        \n",
    "    @property\n",
    "    def memory(self):\n",
    "        return self._memory\n",
    "        \n",
    "    @property\n",
    "    def prompt_key(self):\n",
    "        return self._prompt_key\n",
    "        \n",
    "    @property\n",
    "    def use_chat_history(self):\n",
    "        return self._use_chat_history\n",
    "\n",
    "    @property\n",
    "    def llm(self):\n",
    "        return ChatOpenAI(\n",
    "            model_name=self.llm_model,\n",
    "            temperature=self.temperature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "24f00835-7154-4568-8dca-d325d87531ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_config = BotConfig()\n",
    "\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "            llm=OpenAI(temperature=0),\n",
    "            chat_history=ChatMessageHistory(),\n",
    "            return_messages=True,\n",
    "            memory_key=\"chat_history\",\n",
    "            input_key=\"human_input\",\n",
    "            human_prefix=\"Human\",\n",
    "            ai_prefix=\"AI\",\n",
    "        )\n",
    "\n",
    "standalone_handler = StandaloneHandler(llm_model=_config.LLM_MODEL_NAME, memory=memory, verbose=False)\n",
    "\n",
    "intention_handler = IntentionHandler(llm_model=_config.LLM_MODEL_NAME, memory=memory, verbose=False)\n",
    "\n",
    "message = \"Olá\"\n",
    "\n",
    "improved_message = standalone_handler.predict(message)\n",
    "\n",
    "intension = intention_answerer.predict(improved_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c75cbb2-b60f-4b2d-b5ca-22358181124b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inicio de conversa'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e414755b-991d-42ff-8d86-913611531499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inicio de conversa'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "90964f60-a66d-4f8a-9ceb-0db83698ba84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryBufferMemory(llm=OpenAI(client=<openai.resources.completions.Completions object at 0x7fb0059f1550>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7fb006af6950>, temperature=0.0, openai_api_key='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', openai_proxy=''), input_key='human_input', return_messages=True, memory_key='chat_history')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standalone_answerer.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae262a50-57d7-4185-b2c1-7a62992843b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnalise a mensagem do usuario em \"HUMAN INPUT\" e o \"CHAT HISTORY\" e classifique a intencao de acordo com as seguintes categorias:\n",
      "\n",
      "- \"Inicio de conversa\": Saudacoes e cumprimentos do usuario, reconheca frases como \"oi\", \"ola\", \"bom dia\", \"tudo bem:\", etc.\n",
      "- \"Consulta de conteudo\": Perguntas sobre noticias da base de dados, reconheca trechos como \"quais sao as ultimas noticias\", \"o que foi reportado no bairro\", etc.\n",
      "- \"\": QUALQUER PERGUNTA QUE NAO SE ENCAIXE NAS CATEGORIAS ACIMA, ou que nao possa ser respondida com o contexto disponivel na base de dados, a qual contem noticias de Pocos de Caldas e regiao.\n",
      "\n",
      "Escolha apenas uma das opcoes. Sua resposta deve conter APENAS a categoria.\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Olá! Como posso ajudar você hoje?`\n",
      "\n",
      "IA:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Inicio de conversa'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intention_answerer.predict('Olá! Como posso ajudar você hoje?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f940324-8a73-4a5b-bfb9-70eecd80c6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74f19042-9334-48f8-afb2-ad5f49495834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'human_input'], template='Analise a mensagem do usuario em \"HUMAN INPUT\" e o \"CHAT HISTORY\" e classifique a intencao de acordo com as seguintes categorias:\\n\\n- \"Inicio de conversa\": Saudacoes e cumprimentos do usuario, reconheca frases como \"oi\", \"ola\", \"bom dia\", \"tudo bem:\", etc.\\n- \"Consulta de conteudo\": Perguntas sobre noticias da base de dados, reconheca trechos como \"quais sao as ultimas noticias\", \"o que foi reportado no bairro\", etc.\\n- \"\": QUALQUER PERGUNTA QUE NAO SE ENCAIXE NAS CATEGORIAS ACIMA, ou que nao possa ser respondida com o contexto disponivel na base de dados, a qual contem noticias de Pocos de Caldas e regiao.\\n\\nEscolha apenas uma das opcoes. Sua resposta deve conter APENAS a categoria.\\n\\n## CHAT HISTORY\\n```{history}```\\n\\n## HUMAN INPUT\\n`{human_input}`\\n\\nIA:')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intention_answerer.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "019dad9e-7fa3-4b0c-93d0-28b03771ba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standalone_answerer.get_chat_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ec646e9-03e6-4a09-a22b-09334fed5df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryBufferMemory(llm=OpenAI(client=<openai.resources.completions.Completions object at 0x7fb0057d1b50>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7fb005861890>, temperature=0.0, openai_api_key='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', openai_proxy=''), input_key='human_input', return_messages=True, memory_key='chat_history')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standalone_answerer.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ea9151f-1f24-4edd-8424-c500c7830354",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intention_answerer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mintention_answerer\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOlá\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intention_answerer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c44bd80-a1d3-4eb9-8577-1ebee3c08366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mVoce vai receber uma pergunta de follow up do usuario, que pode nao ter muitos detalhes.\n",
      "O usuario quer realizar consultas na base de dados que contem noticias de Pocos de Caldas e regiao.\n",
      "REESCREVA a frase do HUMAN INPUT para que ela possa ser considerada uma pergunta independente.\n",
      "Inclua o maximo de detalhes possivel a partir do CHAT HISTORY, como contexto, data, titulo e autor da noticia.\n",
      "NAO RESPONDA AO USUARIO, APENAS REESCREVA A PERGUNTA.\n",
      "Sua resposta deve conter apenas a pergunta reescrita.\n",
      "\n",
      "## CHAT HISTORY\n",
      "``````\n",
      "\n",
      "## HUMAN INPUT\n",
      "`Olá`\n",
      "\n",
      "IA:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá! Como posso ajudar você hoje?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standalone_answerer.predict(\"Olá\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5b1fd-ffb4-468d-af99-786814207dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a0de62e-d225-43ab-a966-535d8960dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import resources\n",
    "\n",
    "\n",
    "def get_prompt(key):\n",
    "    filepath = str(resources.files(\"bot.prompts\").joinpath(f\"{key}.json\"))\n",
    "    return load_prompt(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b257cb9e-a3be-4971-9cc2-12eb683294be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'human_input'], template='Voce vai receber uma pergunta de follow up do usuario, que pode nao ter muitos detalhes.\\nO usuario quer realizar consultas na base de dados que contem noticias de Pocos de Caldas e regiao.\\nREESCREVA a frase do HUMAN INPUT para que ela possa ser considerada uma pergunta independente.\\nInclua o maximo de detalhes possivel a partir do CHAT HISTORY, como contexto, data, titulo e autor da noticia.\\nNAO RESPONDA AO USUARIO, APENAS REESCREVA A PERGUNTA.\\nSua resposta deve conter apenas a pergunta reescrita.\\n\\n## CHAT HISTORY\\n```{history}```\\n\\n## HUMAN INPUT\\n`{human_input}`\\n\\nIA:')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "get_prompt(\"prompt_standalone_question\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
